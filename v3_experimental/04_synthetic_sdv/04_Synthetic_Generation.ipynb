{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üß¨ Generaci√≥n de Datos Sint√©ticos con SDV\n",
                "\n",
                "**Versi√≥n:** v3_experimental  \n",
                "**Rol:** Data Engineer (Synthetic Data)  \n",
                "**Fecha:** 2026-01-08\n",
                "\n",
                "---\n",
                "\n",
                "## Objetivo\n",
                "\n",
                "Generar datos sint√©ticos tabulares usando **GaussianCopulaSynthesizer** de SDV para aumentar el dataset de entrenamiento.\n",
                "\n",
                "## M√©todo\n",
                "\n",
                "**GaussianCopula** es el m√©todo recomendado para datasets peque√±os (<1000 filas) porque:\n",
                "- No requiere muchos datos para aprender distribuciones\n",
                "- Captura correlaciones entre variables\n",
                "- Es estable y reproducible\n",
                "\n",
                "## Restricciones\n",
                "\n",
                "> ‚ö†Ô∏è **CERO LEAKAGE**: Solo se usa el archivo de Train. El Test est√° sellado.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# ==============================================================================\n",
                "# CONFIGURACI√ìN Y DEPENDENCIAS\n",
                "# ==============================================================================\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import json\n",
                "from pathlib import Path\n",
                "from datetime import datetime\n",
                "\n",
                "# SDV\n",
                "from sdv.metadata import SingleTableMetadata\n",
                "from sdv.single_table import GaussianCopulaSynthesizer\n",
                "from sdv.evaluation.single_table import evaluate_quality\n",
                "\n",
                "# Configuraci√≥n\n",
                "RANDOM_STATE = 42\n",
                "np.random.seed(RANDOM_STATE)\n",
                "\n",
                "# Paths\n",
                "DATA_DIR = Path(\"../../v2/data/processed\")\n",
                "OUTPUT_DIR = Path(\".\")\n",
                "\n",
                "# Cu√°ntas filas sint√©ticas generar\n",
                "N_SYNTHETIC = 1000\n",
                "\n",
                "print(\"‚úÖ Dependencias cargadas\")\n",
                "print(f\"   SDV GaussianCopula\")\n",
                "print(f\"   Random State: {RANDOM_STATE}\")\n",
                "print(f\"   N Sint√©tico: {N_SYNTHETIC}\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Carga de Datos de Entrenamiento"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# ==============================================================================\n",
                "# CARGA DE DATOS (SOLO TRAIN - CERO LEAKAGE)\n",
                "# ==============================================================================\n",
                "\n",
                "train_df = pd.read_parquet(DATA_DIR / \"train_final.parquet\")\n",
                "\n",
                "print(f\"üìä Datos cargados (SOLO TRAIN):\")\n",
                "print(f\"   Shape: {train_df.shape}\")\n",
                "print(f\"   Columnas: {len(train_df.columns)}\")\n",
                "\n",
                "# Verificar columnas zero-variance a excluir\n",
                "zero_var_cols = []\n",
                "for col in train_df.columns:\n",
                "    if train_df[col].nunique() <= 1:\n",
                "        zero_var_cols.append(col)\n",
                "        \n",
                "print(f\"\\n‚ö†Ô∏è Columnas zero-variance detectadas: {zero_var_cols}\")\n",
                "print(f\"   (Ser√°n excluidas del sintetizador)\")\n",
                "\n",
                "# Crear dataframe limpio para s√≠ntesis\n",
                "train_clean = train_df.drop(columns=zero_var_cols, errors='ignore')\n",
                "print(f\"\\nüìã Dataset para s√≠ntesis: {train_clean.shape}\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Definici√≥n de Metadatos SDV"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# ==============================================================================\n",
                "# DEFINICI√ìN DE METADATOS\n",
                "# ==============================================================================\n",
                "\n",
                "print(\"üìù Definiendo metadatos para SDV...\")\n",
                "\n",
                "# Crear metadata autom√°ticamente\n",
                "metadata = SingleTableMetadata()\n",
                "metadata.detect_from_dataframe(train_clean)\n",
                "\n",
                "# Mostrar tipos detectados\n",
                "print(f\"\\nüìã Tipos detectados:\")\n",
                "for col, info in metadata.columns.items():\n",
                "    sdtype = info.get('sdtype', 'unknown')\n",
                "    print(f\"   {col}: {sdtype}\")\n",
                "    \n",
                "# Verificar metadata\n",
                "metadata.validate()\n",
                "print(f\"\\n‚úÖ Metadatos validados correctamente\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# ==============================================================================\n",
                "# AJUSTE MANUAL DE METADATOS (si es necesario)\n",
                "# ==============================================================================\n",
                "\n",
                "# Asegurar que 'event' sea categ√≥rico/booleano\n",
                "if 'event' in metadata.columns:\n",
                "    metadata.update_column('event', sdtype='categorical')\n",
                "    print(\"‚úèÔ∏è 'event' ajustado a categorical\")\n",
                "\n",
                "# Asegurar que 'duration' sea num√©rico\n",
                "if 'duration' in metadata.columns:\n",
                "    metadata.update_column('duration', sdtype='numerical')\n",
                "    print(\"‚úèÔ∏è 'duration' ajustado a numerical\")\n",
                "\n",
                "# Asegurar que binarios tech_* sean categ√≥ricos\n",
                "binary_cols = [c for c in train_clean.columns if c.startswith('tech_') or c == 'genero_m']\n",
                "for col in binary_cols:\n",
                "    if col in metadata.columns:\n",
                "        metadata.update_column(col, sdtype='categorical')\n",
                "\n",
                "print(f\"‚úèÔ∏è {len(binary_cols)} columnas binarias ajustadas a categorical\")\n",
                "\n",
                "# Validar de nuevo\n",
                "metadata.validate()\n",
                "print(\"\\n‚úÖ Metadatos actualizados y validados\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Entrenamiento del Sintetizador"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# ==============================================================================\n",
                "# CONFIGURAR Y ENTRENAR GAUSSIANCOPULASYNTHESIZER\n",
                "# ==============================================================================\n",
                "\n",
                "print(\"üîß Configurando GaussianCopulaSynthesizer...\")\n",
                "\n",
                "synthesizer = GaussianCopulaSynthesizer(\n",
                "    metadata,\n",
                "    enforce_min_max_values=True,\n",
                "    enforce_rounding=True,\n",
                "    numerical_distributions={\n",
                "        'duration': 'truncnorm',  # Truncated normal para evitar negativos\n",
                "        'edad': 'truncnorm'\n",
                "    },\n",
                "    default_distribution='norm'\n",
                ")\n",
                "\n",
                "print(\"\\nüèãÔ∏è Entrenando sintetizador...\")\n",
                "synthesizer.fit(train_clean)\n",
                "\n",
                "print(\"\\n‚úÖ Sintetizador entrenado exitosamente\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Generaci√≥n de Datos Sint√©ticos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# ==============================================================================\n",
                "# GENERAR DATOS SINT√âTICOS\n",
                "# ==============================================================================\n",
                "\n",
                "print(f\"üß¨ Generando {N_SYNTHETIC} filas sint√©ticas...\")\n",
                "\n",
                "synthetic_df = synthesizer.sample(num_rows=N_SYNTHETIC)\n",
                "\n",
                "print(f\"\\nüìä Datos sint√©ticos generados:\")\n",
                "print(f\"   Shape: {synthetic_df.shape}\")\n",
                "print(f\"\\n   Primeras filas:\")\n",
                "print(synthetic_df.head())"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Post-Procesamiento"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# ==============================================================================\n",
                "# POST-PROCESAMIENTO: ASEGURAR RESTRICCIONES DE DOMINIO\n",
                "# ==============================================================================\n",
                "\n",
                "print(\"üîß Aplicando post-procesamiento...\")\n",
                "\n",
                "# 1. Duration debe ser > 0\n",
                "min_duration = train_clean['duration'].min()\n",
                "if 'duration' in synthetic_df.columns:\n",
                "    before = (synthetic_df['duration'] <= 0).sum()\n",
                "    synthetic_df['duration'] = synthetic_df['duration'].clip(lower=min_duration)\n",
                "    print(f\"   ‚úÖ duration: {before} valores corregidos (clip a {min_duration:.2f})\")\n",
                "\n",
                "# 2. Event debe ser 0 o 1\n",
                "if 'event' in synthetic_df.columns:\n",
                "    synthetic_df['event'] = synthetic_df['event'].round().astype(int).clip(0, 1)\n",
                "    print(f\"   ‚úÖ event: convertido a binario {synthetic_df['event'].unique()}\")\n",
                "\n",
                "# 3. Edad debe estar en rango razonable\n",
                "if 'edad' in synthetic_df.columns:\n",
                "    min_edad = train_clean['edad'].min()\n",
                "    max_edad = train_clean['edad'].max()\n",
                "    synthetic_df['edad'] = synthetic_df['edad'].clip(min_edad, max_edad).round().astype(int)\n",
                "    print(f\"   ‚úÖ edad: clip a [{min_edad}, {max_edad}]\")\n",
                "\n",
                "# 4. Columnas binarias tech_* deben ser 0 o 1\n",
                "binary_cols = [c for c in synthetic_df.columns if c.startswith('tech_') or c == 'genero_m']\n",
                "for col in binary_cols:\n",
                "    synthetic_df[col] = synthetic_df[col].round().astype(int).clip(0, 1)\n",
                "print(f\"   ‚úÖ {len(binary_cols)} columnas binarias convertidas a 0/1\")\n",
                "\n",
                "# 5. Habilidades hab_* deben estar en [0, 1]\n",
                "hab_cols = [c for c in synthetic_df.columns if c.startswith('hab_')]\n",
                "for col in hab_cols:\n",
                "    # Redondear a valores v√°lidos: 0, 0.25, 0.5, 0.75, 1.0\n",
                "    synthetic_df[col] = (synthetic_df[col] * 4).round() / 4\n",
                "    synthetic_df[col] = synthetic_df[col].clip(0, 1)\n",
                "print(f\"   ‚úÖ {len(hab_cols)} columnas hab_* normalizadas a [0, 0.25, 0.5, 0.75, 1.0]\")\n",
                "\n",
                "print(\"\\n‚úÖ Post-procesamiento completado\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Validaci√≥n de Calidad"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# ==============================================================================\n",
                "# VALIDACI√ìN DE CALIDAD SDV\n",
                "# ==============================================================================\n",
                "\n",
                "print(\"üìä Evaluando calidad de los datos sint√©ticos...\")\n",
                "\n",
                "try:\n",
                "    quality_report = evaluate_quality(\n",
                "        real_data=train_clean,\n",
                "        synthetic_data=synthetic_df,\n",
                "        metadata=metadata\n",
                "    )\n",
                "    \n",
                "    overall_score = quality_report.get_score()\n",
                "    print(f\"\\nüèÜ Score de Calidad General: {overall_score:.4f}\")\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"‚ö†Ô∏è No se pudo calcular el score de calidad: {e}\")\n",
                "    overall_score = None"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# ==============================================================================\n",
                "# COMPARACI√ìN ESTAD√çSTICA\n",
                "# ==============================================================================\n",
                "\n",
                "print(\"üìä Comparaci√≥n estad√≠stica Real vs Sint√©tico:\")\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "\n",
                "# Comparar estad√≠sticas clave\n",
                "comparison_cols = ['duration', 'event', 'edad']\n",
                "\n",
                "for col in comparison_cols:\n",
                "    if col in train_clean.columns and col in synthetic_df.columns:\n",
                "        real_mean = train_clean[col].mean()\n",
                "        synth_mean = synthetic_df[col].mean()\n",
                "        real_std = train_clean[col].std()\n",
                "        synth_std = synthetic_df[col].std()\n",
                "        \n",
                "        print(f\"\\n{col}:\")\n",
                "        print(f\"   Real:      Œº={real_mean:.3f}, œÉ={real_std:.3f}\")\n",
                "        print(f\"   Sint√©tico: Œº={synth_mean:.3f}, œÉ={synth_std:.3f}\")\n",
                "        print(f\"   Œî mean:    {abs(real_mean - synth_mean):.3f}\")\n",
                "\n",
                "# Comparar tasa de eventos\n",
                "if 'event' in train_clean.columns:\n",
                "    real_event_rate = train_clean['event'].mean()\n",
                "    synth_event_rate = synthetic_df['event'].mean()\n",
                "    print(f\"\\nEvent Rate:\")\n",
                "    print(f\"   Real:      {real_event_rate:.1%}\")\n",
                "    print(f\"   Sint√©tico: {synth_event_rate:.1%}\")\n",
                "    print(f\"   Œî:         {abs(real_event_rate - synth_event_rate):.1%}\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. Guardar Resultados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# ==============================================================================\n",
                "# GUARDAR DATOS SINT√âTICOS Y MODELO\n",
                "# ==============================================================================\n",
                "\n",
                "print(\"üíæ Guardando resultados...\")\n",
                "\n",
                "# 1. Guardar datos sint√©ticos\n",
                "synthetic_df.to_parquet(OUTPUT_DIR / \"synthetic_data_copula.parquet\", index=False)\n",
                "print(f\"   ‚úÖ synthetic_data_copula.parquet ({len(synthetic_df)} filas)\")\n",
                "\n",
                "# 2. Guardar modelo sintetizador\n",
                "synthesizer.save(OUTPUT_DIR / \"synthesizer_model.pkl\")\n",
                "print(f\"   ‚úÖ synthesizer_model.pkl\")\n",
                "\n",
                "# 3. Guardar metadatos\n",
                "metadata.save_to_json(OUTPUT_DIR / \"synthesizer_metadata.json\")\n",
                "print(f\"   ‚úÖ synthesizer_metadata.json\")\n",
                "\n",
                "# 4. Guardar reporte de generaci√≥n\n",
                "report = {\n",
                "    \"metadata\": {\n",
                "        \"date\": datetime.now().isoformat(),\n",
                "        \"method\": \"GaussianCopulaSynthesizer\",\n",
                "        \"sdv_version\": \"1.32.0\",\n",
                "        \"random_state\": RANDOM_STATE\n",
                "    },\n",
                "    \"input\": {\n",
                "        \"n_real\": len(train_clean),\n",
                "        \"n_features\": len(train_clean.columns),\n",
                "        \"excluded_cols\": zero_var_cols\n",
                "    },\n",
                "    \"output\": {\n",
                "        \"n_synthetic\": len(synthetic_df),\n",
                "        \"quality_score\": float(overall_score) if overall_score else None\n",
                "    },\n",
                "    \"statistics_comparison\": {\n",
                "        \"duration\": {\n",
                "            \"real_mean\": float(train_clean['duration'].mean()),\n",
                "            \"synth_mean\": float(synthetic_df['duration'].mean()),\n",
                "            \"real_std\": float(train_clean['duration'].std()),\n",
                "            \"synth_std\": float(synthetic_df['duration'].std())\n",
                "        },\n",
                "        \"event_rate\": {\n",
                "            \"real\": float(train_clean['event'].mean()),\n",
                "            \"synthetic\": float(synthetic_df['event'].mean())\n",
                "        }\n",
                "    },\n",
                "    \"files_generated\": [\n",
                "        \"synthetic_data_copula.parquet\",\n",
                "        \"synthesizer_model.pkl\",\n",
                "        \"synthesizer_metadata.json\"\n",
                "    ]\n",
                "}\n",
                "\n",
                "with open(OUTPUT_DIR / \"generation_report.json\", 'w') as f:\n",
                "    json.dump(report, f, indent=2)\n",
                "print(f\"   ‚úÖ generation_report.json\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"üéâ GENERACI√ìN SINT√âTICA COMPLETADA\")\n",
                "print(\"=\"*50)"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Resumen\n",
                "\n",
                "### Archivos Generados\n",
                "\n",
                "| Archivo | Descripci√≥n |\n",
                "|---------|-------------|\n",
                "| `synthetic_data_copula.parquet` | 1000 filas sint√©ticas |\n",
                "| `synthesizer_model.pkl` | Modelo GaussianCopula entrenado |\n",
                "| `synthesizer_metadata.json` | Metadatos SDV |\n",
                "| `generation_report.json` | Reporte de generaci√≥n |\n",
                "\n",
                "### Siguiente Paso\n",
                "\n",
                "**Prompt 5: Entrenamiento con Datos Aumentados** - Entrenar modelos con combinaciones de datos reales y sint√©ticos.\n",
                "\n",
                "---"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}