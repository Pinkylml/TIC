{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ† EvaluaciÃ³n TSTR: XGBoost-AFT\n",
                "\n",
                "**VersiÃ³n:** v3_experimental  \n",
                "**Rol:** Model Evaluator  \n",
                "**Fecha:** 2026-01-08\n",
                "\n",
                "---\n",
                "\n",
                "## Objetivo\n",
                "\n",
                "Comparar el rendimiento de XGBoost-AFT (Accelerated Failure Time) entrenado con:\n",
                "1. **Baseline**: Solo datos reales\n",
                "2. **Copula**: Real + 100% SintÃ©tico (Global)\n",
                "3. **Advanced**: Real + 100% SintÃ©tico (Condicional)\n",
                "\n",
                "## MetodologÃ­a: TSTR\n",
                "\n",
                "**Train on Synthetic, Test on Real**\n",
                "- Todos los modelos se evalÃºan en el **mismo Test Set Real**\n",
                "- XGBoost-AFT usa `y_lower` y `y_upper` para censura\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==============================================================================\n",
                "# CONFIGURACIÃ“N Y DEPENDENCIAS\n",
                "# ==============================================================================\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import json\n",
                "from pathlib import Path\n",
                "from datetime import datetime\n",
                "\n",
                "# XGBoost\n",
                "import xgboost as xgb\n",
                "\n",
                "# Survival metrics\n",
                "from sksurv.metrics import concordance_index_censored\n",
                "\n",
                "# ConfiguraciÃ³n\n",
                "RANDOM_STATE = 42\n",
                "np.random.seed(RANDOM_STATE)\n",
                "\n",
                "# Paths\n",
                "DATA_DIR = Path(\"../../v2/data/processed\")\n",
                "SYNTH_GLOBAL_PATH = Path(\"../04_synthetic_sdv/synthetic_data_copula.parquet\")\n",
                "SYNTH_ADVANCED_PATH = Path(\"../05_synthetic_advanced/synthetic_data_advanced.parquet\")\n",
                "OUTPUT_DIR = Path(\".\")\n",
                "\n",
                "print(\"âœ… Dependencias cargadas\")\n",
                "print(f\"   Random State: {RANDOM_STATE}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Carga de Datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==============================================================================\n",
                "# CARGA DE DATOS\n",
                "# ==============================================================================\n",
                "\n",
                "# Datos reales\n",
                "train_real = pd.read_parquet(DATA_DIR / \"train_final.parquet\")\n",
                "test_real = pd.read_parquet(DATA_DIR / \"test_final.parquet\")\n",
                "\n",
                "# Datos sintÃ©ticos\n",
                "synth_global = pd.read_parquet(SYNTH_GLOBAL_PATH)\n",
                "synth_advanced = pd.read_parquet(SYNTH_ADVANCED_PATH)\n",
                "\n",
                "print(f\"ðŸ“Š Datos cargados:\")\n",
                "print(f\"   Train Real:      {train_real.shape}\")\n",
                "print(f\"   Test Real:       {test_real.shape}\")\n",
                "print(f\"   Synth Global:    {synth_global.shape}\")\n",
                "print(f\"   Synth Advanced:  {synth_advanced.shape}\")\n",
                "\n",
                "# Identificar columnas\n",
                "target_cols = ['duration', 'event']\n",
                "zero_var_cols = ['tech_python', 'tech_big_data']\n",
                "\n",
                "# Usar solo columnas comunes\n",
                "common_cols = list(set(train_real.columns) & set(synth_global.columns) & set(synth_advanced.columns))\n",
                "feature_cols = [c for c in common_cols if c not in target_cols + zero_var_cols]\n",
                "\n",
                "print(f\"\\n   Features comunes: {len(feature_cols)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Preparar Sets de Entrenamiento"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==============================================================================\n",
                "# CREAR 3 SETS DE ENTRENAMIENTO\n",
                "# ==============================================================================\n",
                "\n",
                "n_real = len(train_real)\n",
                "\n",
                "# Set 1: Solo Real (Baseline)\n",
                "set_baseline = train_real.copy()\n",
                "\n",
                "# Set 2: Real + SintÃ©tico Global (100%)\n",
                "synth_sample_global = synth_global.sample(n=n_real, random_state=RANDOM_STATE)\n",
                "set_copula = pd.concat([train_real, synth_sample_global], ignore_index=True)\n",
                "\n",
                "# Set 3: Real + SintÃ©tico Advanced (100%)\n",
                "synth_sample_advanced = synth_advanced.sample(n=n_real, random_state=RANDOM_STATE)\n",
                "set_advanced = pd.concat([train_real, synth_sample_advanced], ignore_index=True)\n",
                "\n",
                "print(f\"ðŸ“Š Sets de Entrenamiento Creados:\")\n",
                "print(f\"   Baseline (Real Only):    n={len(set_baseline)}\")\n",
                "print(f\"   Copula (Real + Global):  n={len(set_copula)}\")\n",
                "print(f\"   Advanced (Real + Cond):  n={len(set_advanced)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==============================================================================\n",
                "# PREPARAR DMatrix PARA XGBOOST-AFT\n",
                "# ==============================================================================\n",
                "\n",
                "def prepare_xgb_data(df, feature_cols):\n",
                "    \"\"\"\n",
                "    Prepara datos para XGBoost-AFT con y_lower y y_upper.\n",
                "    - Evento (event=1): y_lower = y_upper = log(duration)\n",
                "    - Censurado (event=0): y_lower = log(duration), y_upper = +inf\n",
                "    \"\"\"\n",
                "    X = df[feature_cols].values\n",
                "    duration = df['duration'].values\n",
                "    event = df['event'].values.astype(bool)\n",
                "    \n",
                "    # Log-transform\n",
                "    y_lower = np.log(duration)\n",
                "    y_upper = np.where(event, y_lower, np.inf)\n",
                "    \n",
                "    # Crear DMatrix\n",
                "    dmatrix = xgb.DMatrix(X)\n",
                "    dmatrix.set_float_info('label_lower_bound', y_lower)\n",
                "    dmatrix.set_float_info('label_upper_bound', y_upper)\n",
                "    \n",
                "    return dmatrix, duration, event\n",
                "\n",
                "# Preparar sets\n",
                "dtrain_baseline, dur_baseline, evt_baseline = prepare_xgb_data(set_baseline, feature_cols)\n",
                "dtrain_copula, dur_copula, evt_copula = prepare_xgb_data(set_copula, feature_cols)\n",
                "dtrain_advanced, dur_advanced, evt_advanced = prepare_xgb_data(set_advanced, feature_cols)\n",
                "\n",
                "# Preparar test\n",
                "dtest, dur_test, evt_test = prepare_xgb_data(test_real, feature_cols)\n",
                "\n",
                "print(f\"\\nâœ… DMatrix preparados:\")\n",
                "print(f\"   Baseline: {dtrain_baseline.num_row()} filas\")\n",
                "print(f\"   Copula:   {dtrain_copula.num_row()} filas\")\n",
                "print(f\"   Advanced: {dtrain_advanced.num_row()} filas\")\n",
                "print(f\"   Test:     {dtest.num_row()} filas\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Entrenar XGBoost-AFT"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==============================================================================\n",
                "# ENTRENAR XGBoost-AFT PARA CADA SET\n",
                "# ==============================================================================\n",
                "\n",
                "# ParÃ¡metros AFT\n",
                "xgb_params = {\n",
                "    'objective': 'survival:aft',\n",
                "    'eval_metric': 'aft-nloglik',\n",
                "    'aft_loss_distribution': 'normal',\n",
                "    'aft_loss_distribution_scale': 1.0,\n",
                "    'max_depth': 3,\n",
                "    'learning_rate': 0.1,\n",
                "    'seed': RANDOM_STATE\n",
                "}\n",
                "NUM_ROUNDS = 100\n",
                "\n",
                "results = []\n",
                "\n",
                "def train_and_evaluate(dtrain, dtest, dur_test, evt_test, scenario_name, n_train, synth_ratio):\n",
                "    \"\"\"Entrena XGB-AFT y evalÃºa.\"\"\"\n",
                "    print(f\"ðŸš€ Entrenando XGBoost-AFT {scenario_name}...\")\n",
                "    \n",
                "    model = xgb.train(\n",
                "        xgb_params,\n",
                "        dtrain,\n",
                "        num_boost_round=NUM_ROUNDS,\n",
                "        evals=[(dtrain, 'train')],\n",
                "        verbose_eval=False\n",
                "    )\n",
                "    \n",
                "    # PredicciÃ³n: log-time â†’ invertir para risk\n",
                "    pred_logtime = model.predict(dtest)\n",
                "    risk = -pred_logtime  # Mayor riesgo = tiempo mÃ¡s corto\n",
                "    \n",
                "    # C-index\n",
                "    c_index = concordance_index_censored(evt_test, dur_test, risk)[0]\n",
                "    \n",
                "    # Log-likelihood aproximada (evaluar en test)\n",
                "    # Usamos el aft-nloglik del modelo\n",
                "    evals_result = {}\n",
                "    xgb.train(\n",
                "        xgb_params,\n",
                "        dtrain,\n",
                "        num_boost_round=NUM_ROUNDS,\n",
                "        evals=[(dtest, 'test')],\n",
                "        evals_result=evals_result,\n",
                "        verbose_eval=False\n",
                "    )\n",
                "    final_nloglik = evals_result['test']['aft-nloglik'][-1]\n",
                "    \n",
                "    print(f\"   C-index: {c_index:.4f}\")\n",
                "    print(f\"   -Log-Lik: {final_nloglik:.4f}\")\n",
                "    \n",
                "    results.append({\n",
                "        'scenario': scenario_name,\n",
                "        'n_train': int(n_train),\n",
                "        'synthetic_ratio': synth_ratio,\n",
                "        'c_index': float(c_index),\n",
                "        'neg_loglik': float(final_nloglik)\n",
                "    })\n",
                "    \n",
                "    return model\n",
                "\n",
                "# --- Modelo 1: Baseline ---\n",
                "xgb_baseline = train_and_evaluate(\n",
                "    dtrain_baseline, dtest, dur_test, evt_test,\n",
                "    'Baseline (Real Only)', len(set_baseline), '0%'\n",
                ")\n",
                "\n",
                "# --- Modelo 2: Copula ---\n",
                "print()\n",
                "xgb_copula = train_and_evaluate(\n",
                "    dtrain_copula, dtest, dur_test, evt_test,\n",
                "    'Real + Copula (100%)', len(set_copula), '100%'\n",
                ")\n",
                "\n",
                "# --- Modelo 3: Advanced ---\n",
                "print()\n",
                "xgb_advanced = train_and_evaluate(\n",
                "    dtrain_advanced, dtest, dur_test, evt_test,\n",
                "    'Real + Advanced (100%)', len(set_advanced), '100%'\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. ComparaciÃ³n de Resultados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==============================================================================\n",
                "# TABLA DE RESULTADOS\n",
                "# ==============================================================================\n",
                "\n",
                "results_df = pd.DataFrame(results)\n",
                "\n",
                "# Calcular delta vs baseline\n",
                "baseline_cindex = results_df[results_df['scenario'].str.contains('Baseline')]['c_index'].values[0]\n",
                "results_df['delta_vs_baseline'] = results_df['c_index'] - baseline_cindex\n",
                "results_df['improvement'] = results_df['delta_vs_baseline'].apply(\n",
                "    lambda x: 'âœ… Mejora' if x > 0.01 else ('âš ï¸ Similar' if x >= -0.02 else 'âŒ Peor')\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"ðŸ“Š RESULTADOS XGBoost-AFT - TSTR\")\n",
                "print(\"=\"*80)\n",
                "print(f\"\\n{results_df.to_string(index=False)}\")\n",
                "\n",
                "# Identificar mejor modelo\n",
                "best_idx = results_df['c_index'].idxmax()\n",
                "best_model = results_df.loc[best_idx]\n",
                "\n",
                "print(f\"\\nðŸ† Mejor Modelo: {best_model['scenario']}\")\n",
                "print(f\"   C-index: {best_model['c_index']:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==============================================================================\n",
                "# VISUALIZACIÃ“N\n",
                "# ==============================================================================\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "scenarios = results_df['scenario'].values\n",
                "c_indices = results_df['c_index'].values\n",
                "neg_logliks = results_df['neg_loglik'].values\n",
                "colors = ['steelblue', 'darkorange', 'green']\n",
                "\n",
                "# --- C-index ---\n",
                "ax1 = axes[0]\n",
                "bars1 = ax1.bar(range(len(scenarios)), c_indices, color=colors, edgecolor='white', linewidth=2)\n",
                "ax1.axhline(y=0.5, color='red', linestyle='--', linewidth=2, label='Random (0.5)')\n",
                "ax1.axhline(y=baseline_cindex, color='steelblue', linestyle=':', linewidth=2, alpha=0.7, label=f'Baseline ({baseline_cindex:.3f})')\n",
                "\n",
                "for i, (bar, c_idx) in enumerate(zip(bars1, c_indices)):\n",
                "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
                "             f'{c_idx:.4f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
                "\n",
                "ax1.set_xticks(range(len(scenarios)))\n",
                "ax1.set_xticklabels(['Baseline', 'Copula', 'Advanced'], fontsize=10)\n",
                "ax1.set_ylabel('C-index', fontsize=12)\n",
                "ax1.set_title('XGBoost-AFT: C-index por Escenario', fontsize=13, fontweight='bold')\n",
                "ax1.set_ylim(0.3, 0.7)\n",
                "ax1.legend(loc='upper right')\n",
                "ax1.grid(axis='y', alpha=0.3)\n",
                "\n",
                "# --- Neg-LogLik ---\n",
                "ax2 = axes[1]\n",
                "bars2 = ax2.bar(range(len(scenarios)), neg_logliks, color=colors, edgecolor='white', linewidth=2)\n",
                "\n",
                "for i, (bar, nll) in enumerate(zip(bars2, neg_logliks)):\n",
                "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
                "             f'{nll:.2f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
                "\n",
                "ax2.set_xticks(range(len(scenarios)))\n",
                "ax2.set_xticklabels(['Baseline', 'Copula', 'Advanced'], fontsize=10)\n",
                "ax2.set_ylabel('-Log-Likelihood (menor es mejor)', fontsize=12)\n",
                "ax2.set_title('XGBoost-AFT: Neg-LogLik por Escenario', fontsize=13, fontweight='bold')\n",
                "ax2.grid(axis='y', alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(OUTPUT_DIR / 'xgb_comparison.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nâœ… GrÃ¡fico guardado: xgb_comparison.png\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Guardar Resultados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==============================================================================\n",
                "# GUARDAR RESULTADOS\n",
                "# ==============================================================================\n",
                "\n",
                "# CSV\n",
                "results_df.to_csv(OUTPUT_DIR / 'xgb_results.csv', index=False)\n",
                "print(\"ðŸ’¾ Guardado: xgb_results.csv\")\n",
                "\n",
                "# JSON detallado\n",
                "report = {\n",
                "    \"metadata\": {\n",
                "        \"date\": datetime.now().isoformat(),\n",
                "        \"model\": \"XGBoost-AFT\",\n",
                "        \"methodology\": \"TSTR (Train on Synthetic, Test on Real)\",\n",
                "        \"random_state\": RANDOM_STATE\n",
                "    },\n",
                "    \"test_set\": {\n",
                "        \"n\": int(len(dur_test)),\n",
                "        \"event_rate\": float(evt_test.mean())\n",
                "    },\n",
                "    \"xgb_params\": xgb_params,\n",
                "    \"num_rounds\": NUM_ROUNDS,\n",
                "    \"results\": results,\n",
                "    \"best_model\": {\n",
                "        \"scenario\": str(best_model['scenario']),\n",
                "        \"c_index\": float(best_model['c_index']),\n",
                "        \"delta_vs_baseline\": float(best_model['delta_vs_baseline'])\n",
                "    },\n",
                "    \"conclusion\": {\n",
                "        \"synthetic_helps\": bool(results_df[results_df['scenario'] != 'Baseline (Real Only)']['c_index'].max() > baseline_cindex),\n",
                "        \"best_synthetic_method\": str(results_df.iloc[results_df['c_index'].idxmax()]['scenario'])\n",
                "    }\n",
                "}\n",
                "\n",
                "with open(OUTPUT_DIR / 'xgb_evaluation_report.json', 'w') as f:\n",
                "    json.dump(report, f, indent=2)\n",
                "print(\"ðŸ’¾ Guardado: xgb_evaluation_report.json\")\n",
                "\n",
                "# Guardar modelos\n",
                "xgb_baseline.save_model(OUTPUT_DIR / 'xgb_baseline.json')\n",
                "xgb_copula.save_model(OUTPUT_DIR / 'xgb_copula.json')\n",
                "xgb_advanced.save_model(OUTPUT_DIR / 'xgb_advanced.json')\n",
                "print(\"ðŸ’¾ Modelos guardados: xgb_*.json\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"ðŸŽ‰ EVALUACIÃ“N XGBoost-AFT COMPLETADA\")\n",
                "print(\"=\"*50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Resumen\n",
                "\n",
                "### Resultados TSTR - XGBoost-AFT\n",
                "\n",
                "| Escenario | n Train | C-index | -LogLik | Î” vs Baseline |\n",
                "|-----------|---------|---------|---------|---------------|\n",
                "| Baseline | 296 | ? | ? | â€” |\n",
                "| Copula | 592 | ? | ? | ? |\n",
                "| Advanced | 592 | ? | ? | ? |\n",
                "\n",
                "### InterpretaciÃ³n\n",
                "\n",
                "- **Î” > 0**: La data sintÃ©tica mejora el modelo\n",
                "- **Î” â‰ˆ 0**: La data sintÃ©tica no afecta\n",
                "- **Î” < 0**: La data sintÃ©tica degrada el modelo\n",
                "\n",
                "### Siguiente Paso\n",
                "\n",
                "**Prompt 10**: Conclusiones finales y reporte consolidado.\n",
                "\n",
                "---"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}