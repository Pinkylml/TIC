{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d8ea3b",
   "metadata": {},
   "source": [
    "# ÔøΩÔøΩ Hyperparameter Tuning: RSF vs XGBoost-AFT\n",
    "\n",
    "**Objetivo**: Encontrar la mejor configuraci√≥n de hiperpar√°metros para modelos de supervivencia.\n",
    "\n",
    "**Modelos**:\n",
    "- Random Survival Forest (RSF)\n",
    "- XGBoost-AFT (Accelerated Failure Time)\n",
    "\n",
    "**Output**:\n",
    "- `models/best_rsf.pkl`\n",
    "- `models/best_xgb_aft.json`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "774a3057",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:10:01.907491Z",
     "iopub.status.busy": "2026-01-09T01:10:01.907244Z",
     "iopub.status.idle": "2026-01-09T01:10:02.566692Z",
     "shell.execute_reply": "2026-01-09T01:10:02.565912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datos cargados: 296 registros | columnas: 63\n",
      "   Duration range: [0.18, 30.00]\n",
      "   Event rate: 45.6%\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 0. CONFIGURACI√ìN Y CARGA\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.util import Surv\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, ParameterGrid\n",
    "\n",
    "# ----------------------------\n",
    "# Reproducibilidad b√°sica\n",
    "# ----------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ----------------------------\n",
    "# Paths y checks\n",
    "# ----------------------------\n",
    "# Usamos la versi√≥n corregida (v2) del dataset\n",
    "DATA_PATH = Path(\"data/processed/train_survival_final.parquet\")\n",
    "MODELS_DIR = Path(\"models\")\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå No existe el archivo: {DATA_PATH.resolve()}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Cargar datos\n",
    "# ----------------------------\n",
    "df_train = pd.read_parquet(DATA_PATH)\n",
    "print(f\"‚úÖ Datos cargados: {len(df_train)} registros | columnas: {df_train.shape[1]}\")\n",
    "\n",
    "required_cols = {\"event\", \"duration\"}\n",
    "missing = required_cols - set(df_train.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"‚ùå Faltan columnas requeridas: {missing}\")\n",
    "\n",
    "# Validaci√≥n m√≠nima\n",
    "if (df_train[\"duration\"] <= 0).any():\n",
    "    bad = int((df_train[\"duration\"] <= 0).sum())\n",
    "    raise ValueError(f\"‚ùå Hay {bad} filas con duration <= 0. Corrige antes de entrenar.\")\n",
    "\n",
    "print(f\"   Duration range: [{df_train['duration'].min():.2f}, {df_train['duration'].max():.2f}]\")\n",
    "print(f\"   Event rate: {df_train['event'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e2832c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:10:02.568787Z",
     "iopub.status.busy": "2026-01-09T01:10:02.568499Z",
     "iopub.status.idle": "2026-01-09T01:10:02.575437Z",
     "shell.execute_reply": "2026-01-09T01:10:02.574696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Features (X): 61 columnas\n",
      "‚úÖ Target (y): 296 registros estructurados\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 1. PREPROCESAMIENTO PARA RSF\n",
    "# ==============================================================================\n",
    "cols_to_drop = [\"event\", \"duration\", \"carrera_norm\"]  # meta-data o labels\n",
    "X_train = df_train.drop(columns=[c for c in cols_to_drop if c in df_train.columns])\n",
    "\n",
    "# Si hay columnas no num√©ricas, intenta one-hot autom√°ticamente\n",
    "non_numeric_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "if non_numeric_cols:\n",
    "    print(f\"‚ö†Ô∏è Columnas no num√©ricas detectadas: {non_numeric_cols}\")\n",
    "    print(\"‚û°Ô∏è Aplicando one-hot encoding autom√°tico.\")\n",
    "    X_train = pd.get_dummies(X_train, columns=non_numeric_cols, drop_first=True)\n",
    "\n",
    "# NaNs: imputaci√≥n simple con mediana\n",
    "if X_train.isna().any().any():\n",
    "    print(\"‚ö†Ô∏è Se detectaron NaNs. Aplicando imputaci√≥n (mediana).\")\n",
    "    X_train = X_train.fillna(X_train.median(numeric_only=True))\n",
    "\n",
    "# Formato para Scikit-Survival (RSF)\n",
    "y_sksurv = Surv.from_dataframe(\"event\", \"duration\", df_train)\n",
    "\n",
    "print(f\"‚úÖ Features (X): {X_train.shape[1]} columnas\")\n",
    "print(f\"‚úÖ Target (y): {len(y_sksurv)} registros estructurados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a09f0f",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Tuning Random Survival Forest (RSF)\n",
    "\n",
    "Usamos StratifiedKFold para mantener proporci√≥n de eventos en cada fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb9e332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:10:02.577058Z",
     "iopub.status.busy": "2026-01-09T01:10:02.576871Z",
     "iopub.status.idle": "2026-01-09T01:10:10.895423Z",
     "shell.execute_reply": "2026-01-09T01:10:10.893941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå≤ INICIANDO TUNING DE RSF (puede tardar varios minutos)...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Mejor RSF C-index promedio: 0.6000\n",
      "‚öôÔ∏è Mejores par√°metros RSF: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 20, 'n_estimators': 500}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo RSF guardado en models/best_rsf.pkl\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 2. TUNING RANDOM SURVIVAL FOREST (RSF)\n",
    "# ==============================================================================\n",
    "print(\"üå≤ INICIANDO TUNING DE RSF (puede tardar varios minutos)...\")\n",
    "\n",
    "rsf_param_grid = {\n",
    "    \"n_estimators\": [200, 500],\n",
    "    \"min_samples_leaf\": [5, 10, 20],\n",
    "    \"max_depth\": [None, 10],\n",
    "    \"max_features\": [\"sqrt\"]\n",
    "}\n",
    "\n",
    "# Estratificar por event (proporci√≥n censura estable por fold)\n",
    "y_event = df_train[\"event\"].astype(int).values\n",
    "cv_rsf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "rsf_grid = GridSearchCV(\n",
    "    estimator=RandomSurvivalForest(random_state=SEED, n_jobs=-1),\n",
    "    param_grid=rsf_param_grid,\n",
    "    cv=cv_rsf,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "rsf_grid.fit(X_train, y_sksurv)\n",
    "\n",
    "print(f\"\\nüèÜ Mejor RSF C-index promedio: {rsf_grid.best_score_:.4f}\")\n",
    "print(f\"‚öôÔ∏è Mejores par√°metros RSF: {rsf_grid.best_params_}\")\n",
    "\n",
    "# Guardar mejor modelo RSF\n",
    "joblib.dump(rsf_grid.best_estimator_, MODELS_DIR / \"best_rsf.pkl\")\n",
    "joblib.dump(rsf_grid.best_params_, MODELS_DIR / \"best_rsf_params.pkl\")\n",
    "print(f\"‚úÖ Modelo RSF guardado en {MODELS_DIR / 'best_rsf.pkl'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab046a2",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Tuning XGBoost-AFT\n",
    "\n",
    "XGBoost AFT requiere formato especial de censura:\n",
    "- Evento=1 ‚Üí tiempo exacto `[T, T]`\n",
    "- Evento=0 ‚Üí censura derecha ‚Üí `[T, +inf]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49d2b734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:10:10.898605Z",
     "iopub.status.busy": "2026-01-09T01:10:10.898263Z",
     "iopub.status.idle": "2026-01-09T01:11:08.680522Z",
     "shell.execute_reply": "2026-01-09T01:11:08.679911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ INICIANDO TUNING DE XGBOOST-AFT...\n",
      "Evaluando 32 combinaciones para XGBoost...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ü•á Nuevo mejor (1/32): Loss=17.0652 | Dist=normal | Rounds=39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ü•á Nuevo mejor (2/32): Loss=16.9793 | Dist=normal | Rounds=41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Mejor XGBoost Loss (aft-nloglik): 16.9793\n",
      "‚öôÔ∏è Mejores par√°metros XGB: {'aft_loss_distribution': 'normal', 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'reg_lambda': 5.0, 'objective': 'survival:aft', 'eval_metric': 'aft-nloglik', 'tree_method': 'hist', 'verbosity': 0, 'seed': 42, 'nthread': -1}\n",
      "üîÅ Mejor num_boost_round: 41\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 3. TUNING XGBOOST-AFT (L√≥gica avanzada de censura)\n",
    "# ==============================================================================\n",
    "print(\"üöÄ INICIANDO TUNING DE XGBOOST-AFT...\")\n",
    "\n",
    "def make_aft_bounds(df):\n",
    "    \"\"\"\n",
    "    AFT requiere intervalo [lower, upper]\n",
    "    Evento=1 => tiempo exacto [T, T]\n",
    "    Evento=0 => censura derecha => [T, +inf]\n",
    "    \"\"\"\n",
    "    y_lower = df[\"duration\"].to_numpy(dtype=float)\n",
    "    y_upper = df[\"duration\"].to_numpy(dtype=float)\n",
    "    y_upper[df[\"event\"].to_numpy(dtype=int) == 0] = np.inf\n",
    "    return y_lower, y_upper\n",
    "\n",
    "y_lower, y_upper = make_aft_bounds(df_train)\n",
    "\n",
    "# DMatrix con bounds\n",
    "dtrain = xgb.DMatrix(X_train)\n",
    "dtrain.set_float_info(\"label_lower_bound\", y_lower)\n",
    "dtrain.set_float_info(\"label_upper_bound\", y_upper)\n",
    "\n",
    "# Grid de hiperpar√°metros (reducido para tiempo razonable)\n",
    "xgb_params_grid = {\n",
    "    \"learning_rate\": [0.01, 0.05],\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"min_child_weight\": [1, 3],\n",
    "    \"reg_lambda\": [1.0, 5.0],\n",
    "    \"aft_loss_distribution\": [\"normal\", \"logistic\"],\n",
    "}\n",
    "\n",
    "best_loss_val = float(\"inf\")\n",
    "best_params = None\n",
    "best_num_rounds = None\n",
    "\n",
    "grid = list(ParameterGrid(xgb_params_grid))\n",
    "print(f\"Evaluando {len(grid)} combinaciones para XGBoost...\")\n",
    "\n",
    "for i, params in enumerate(grid, start=1):\n",
    "    current_params = dict(params)\n",
    "    current_params.update({\n",
    "        \"objective\": \"survival:aft\",\n",
    "        \"eval_metric\": \"aft-nloglik\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"verbosity\": 0,\n",
    "        \"seed\": SEED,\n",
    "        \"nthread\": -1\n",
    "    })\n",
    "\n",
    "    cv_results = xgb.cv(\n",
    "        params=current_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=1000,\n",
    "        nfold=5,\n",
    "        stratified=False,\n",
    "        early_stopping_rounds=20,\n",
    "        verbose_eval=False,\n",
    "        seed=SEED\n",
    "    )\n",
    "\n",
    "    # ‚úÖ BUG FIX: la mejor ronda es el argmin, no el total de filas\n",
    "    loss_series = cv_results[\"test-aft-nloglik-mean\"]\n",
    "    mean_loss = float(loss_series.min())\n",
    "    best_round_here = int(loss_series.idxmin() + 1)\n",
    "\n",
    "    if mean_loss < best_loss_val:\n",
    "        best_loss_val = mean_loss\n",
    "        best_params = current_params\n",
    "        best_num_rounds = best_round_here\n",
    "        print(f\"   ü•á Nuevo mejor ({i}/{len(grid)}): Loss={mean_loss:.4f} | \"\n",
    "              f\"Dist={params['aft_loss_distribution']} | Rounds={best_num_rounds}\")\n",
    "\n",
    "print(f\"\\nüèÜ Mejor XGBoost Loss (aft-nloglik): {best_loss_val:.4f}\")\n",
    "print(f\"‚öôÔ∏è Mejores par√°metros XGB: {best_params}\")\n",
    "print(f\"üîÅ Mejor num_boost_round: {best_num_rounds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c60e6b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:11:08.683991Z",
     "iopub.status.busy": "2026-01-09T01:11:08.683794Z",
     "iopub.status.idle": "2026-01-09T01:11:08.746239Z",
     "shell.execute_reply": "2026-01-09T01:11:08.745246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo XGBoost-AFT guardado en models/best_xgb_aft.json\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 4. ENTRENAR MODELO FINAL XGBOOST-AFT\n",
    "# ==============================================================================\n",
    "\n",
    "# Entrenar el modelo con los mejores hiperpar√°metros y rondas √≥ptimas\n",
    "final_xgb = xgb.train(\n",
    "    params=best_params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=best_num_rounds\n",
    ")\n",
    "\n",
    "# Guardar modelo\n",
    "final_xgb.save_model(str(MODELS_DIR / \"best_xgb_aft.json\"))\n",
    "joblib.dump(best_params, MODELS_DIR / \"best_xgb_params.pkl\")\n",
    "print(f\"‚úÖ Modelo XGBoost-AFT guardado en {MODELS_DIR / 'best_xgb_aft.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4addf2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:11:08.748414Z",
     "iopub.status.busy": "2026-01-09T01:11:08.748138Z",
     "iopub.status.idle": "2026-01-09T01:11:08.754595Z",
     "shell.execute_reply": "2026-01-09T01:11:08.753884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä RESUMEN DEL HYPERPARAMETER TUNING\n",
      "======================================================================\n",
      "\n",
      "üå≤ RANDOM SURVIVAL FOREST:\n",
      "   C-index promedio: 0.6000\n",
      "   Mejores par√°metros:\n",
      "      max_depth: None\n",
      "      max_features: sqrt\n",
      "      min_samples_leaf: 20\n",
      "      n_estimators: 500\n",
      "\n",
      "üöÄ XGBOOST-AFT:\n",
      "   Loss (aft-nloglik): 16.9793\n",
      "   Distribuci√≥n ganadora: normal\n",
      "   Mejor num_boost_round: 41\n",
      "\n",
      "üìÅ MODELOS GUARDADOS:\n",
      "   - models/best_rsf.pkl\n",
      "   - models/best_xgb_aft.json\n",
      "\n",
      "======================================================================\n",
      "‚úÖ PROCESO COMPLETADO. Listo para evaluaci√≥n final en test set.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# üìä RESUMEN FINAL\n",
    "# ==============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä RESUMEN DEL HYPERPARAMETER TUNING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüå≤ RANDOM SURVIVAL FOREST:\")\n",
    "print(f\"   C-index promedio: {rsf_grid.best_score_:.4f}\")\n",
    "print(f\"   Mejores par√°metros:\")\n",
    "for k, v in rsf_grid.best_params_.items():\n",
    "    print(f\"      {k}: {v}\")\n",
    "\n",
    "print(f\"\\nüöÄ XGBOOST-AFT:\")\n",
    "print(f\"   Loss (aft-nloglik): {best_loss_val:.4f}\")\n",
    "print(f\"   Distribuci√≥n ganadora: {best_params.get('aft_loss_distribution', 'N/A')}\")\n",
    "print(f\"   Mejor num_boost_round: {best_num_rounds}\")\n",
    "\n",
    "print(f\"\\nüìÅ MODELOS GUARDADOS:\")\n",
    "print(f\"   - models/best_rsf.pkl\")\n",
    "print(f\"   - models/best_xgb_aft.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ PROCESO COMPLETADO. Listo para evaluaci√≥n final en test set.\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
