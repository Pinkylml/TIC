{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d8ea3b",
   "metadata": {},
   "source": [
    "# \ufffd\ufffd Hyperparameter Tuning: RSF vs XGBoost-AFT\n",
    "\n",
    "**Objetivo**: Encontrar la mejor configuraci\u00f3n de hiperpar\u00e1metros para modelos de supervivencia.\n",
    "\n",
    "**Modelos**:\n",
    "- Random Survival Forest (RSF)\n",
    "- XGBoost-AFT (Accelerated Failure Time)\n",
    "\n",
    "**Output**:\n",
    "- `models/best_rsf.pkl`\n",
    "- `models/best_xgb_aft.json`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774a3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 0. CONFIGURACI\u00d3N Y CARGA\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.util import Surv\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, ParameterGrid\n",
    "\n",
    "# ----------------------------\n",
    "# Reproducibilidad b\u00e1sica\n",
    "# ----------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ----------------------------\n",
    "# Paths y checks\n",
    "# ----------------------------\n",
    "# Usamos la versi\u00f3n corregida (v2) del dataset\n",
    "DATA_PATH = Path(\"data/processed/train_survival_final.parquet\")\n",
    "MODELS_DIR = Path(\"models\")\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"\u274c No existe el archivo: {DATA_PATH.resolve()}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Cargar datos\n",
    "# ----------------------------\n",
    "df_train = pd.read_parquet(DATA_PATH)\n",
    "print(f\"\u2705 Datos cargados: {len(df_train)} registros | columnas: {df_train.shape[1]}\")\n",
    "\n",
    "required_cols = {\"event\", \"duration\"}\n",
    "missing = required_cols - set(df_train.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"\u274c Faltan columnas requeridas: {missing}\")\n",
    "\n",
    "# Validaci\u00f3n m\u00ednima\n",
    "if (df_train[\"duration\"] <= 0).any():\n",
    "    bad = int((df_train[\"duration\"] <= 0).sum())\n",
    "    raise ValueError(f\"\u274c Hay {bad} filas con duration <= 0. Corrige antes de entrenar.\")\n",
    "\n",
    "print(f\"   Duration range: [{df_train['duration'].min():.2f}, {df_train['duration'].max():.2f}]\")\n",
    "print(f\"   Event rate: {df_train['event'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e2832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. PREPROCESAMIENTO PARA RSF\n",
    "# ==============================================================================\n",
    "cols_to_drop = [\"event\", \"duration\", \"carrera_norm\"]  # meta-data o labels\n",
    "X_train = df_train.drop(columns=[c for c in cols_to_drop if c in df_train.columns])\n",
    "\n",
    "# Si hay columnas no num\u00e9ricas, intenta one-hot autom\u00e1ticamente\n",
    "non_numeric_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "if non_numeric_cols:\n",
    "    print(f\"\u26a0\ufe0f Columnas no num\u00e9ricas detectadas: {non_numeric_cols}\")\n",
    "    print(\"\u27a1\ufe0f Aplicando one-hot encoding autom\u00e1tico.\")\n",
    "    X_train = pd.get_dummies(X_train, columns=non_numeric_cols, drop_first=True)\n",
    "\n",
    "# NaNs: imputaci\u00f3n simple con mediana\n",
    "if X_train.isna().any().any():\n",
    "    print(\"\u26a0\ufe0f Se detectaron NaNs. Aplicando imputaci\u00f3n (mediana).\")\n",
    "    X_train = X_train.fillna(X_train.median(numeric_only=True))\n",
    "\n",
    "# Formato para Scikit-Survival (RSF)\n",
    "y_sksurv = Surv.from_dataframe(\"event\", \"duration\", df_train)\n",
    "\n",
    "print(f\"\u2705 Features (X): {X_train.shape[1]} columnas\")\n",
    "print(f\"\u2705 Target (y): {len(y_sksurv)} registros estructurados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a09f0f",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Tuning Random Survival Forest (RSF)\n",
    "\n",
    "Usamos StratifiedKFold para mantener proporci\u00f3n de eventos en cada fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb9e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 2. TUNING RANDOM SURVIVAL FOREST (RSF)\n",
    "# ==============================================================================\n",
    "print(\"\ud83c\udf32 INICIANDO TUNING DE RSF (puede tardar varios minutos)...\")\n",
    "\n",
    "rsf_param_grid = {\n",
    "    \"n_estimators\": [200, 500],\n",
    "    \"min_samples_leaf\": [5, 10, 20],\n",
    "    \"max_depth\": [None, 10],\n",
    "    \"max_features\": [\"sqrt\"]\n",
    "}\n",
    "\n",
    "# Estratificar por event (proporci\u00f3n censura estable por fold)\n",
    "y_event = df_train[\"event\"].astype(int).values\n",
    "cv_rsf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "rsf_grid = GridSearchCV(\n",
    "    estimator=RandomSurvivalForest(random_state=SEED, n_jobs=-1),\n",
    "    param_grid=rsf_param_grid,\n",
    "    cv=cv_rsf,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "rsf_grid.fit(X_train, y_sksurv)\n",
    "\n",
    "print(f\"\\n\ud83c\udfc6 Mejor RSF C-index promedio: {rsf_grid.best_score_:.4f}\")\n",
    "print(f\"\u2699\ufe0f Mejores par\u00e1metros RSF: {rsf_grid.best_params_}\")\n",
    "\n",
    "# Guardar mejor modelo RSF\n",
    "joblib.dump(rsf_grid.best_estimator_, MODELS_DIR / \"best_rsf.pkl\")\n",
    "joblib.dump(rsf_grid.best_params_, MODELS_DIR / \"best_rsf_params.pkl\")\n",
    "print(f\"\u2705 Modelo RSF guardado en {MODELS_DIR / 'best_rsf.pkl'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab046a2",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Tuning XGBoost-AFT\n",
    "\n",
    "XGBoost AFT requiere formato especial de censura:\n",
    "- Evento=1 \u2192 tiempo exacto `[T, T]`\n",
    "- Evento=0 \u2192 censura derecha \u2192 `[T, +inf]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d2b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 3. TUNING XGBOOST-AFT (L\u00f3gica avanzada de censura)\n",
    "# ==============================================================================\n",
    "print(\"\ud83d\ude80 INICIANDO TUNING DE XGBOOST-AFT...\")\n",
    "\n",
    "def make_aft_bounds(df):\n",
    "    \"\"\"\n",
    "    AFT requiere intervalo [lower, upper]\n",
    "    Evento=1 => tiempo exacto [T, T]\n",
    "    Evento=0 => censura derecha => [T, +inf]\n",
    "    \"\"\"\n",
    "    y_lower = df[\"duration\"].to_numpy(dtype=float)\n",
    "    y_upper = df[\"duration\"].to_numpy(dtype=float)\n",
    "    y_upper[df[\"event\"].to_numpy(dtype=int) == 0] = np.inf\n",
    "    return y_lower, y_upper\n",
    "\n",
    "y_lower, y_upper = make_aft_bounds(df_train)\n",
    "\n",
    "# DMatrix con bounds\n",
    "dtrain = xgb.DMatrix(X_train)\n",
    "dtrain.set_float_info(\"label_lower_bound\", y_lower)\n",
    "dtrain.set_float_info(\"label_upper_bound\", y_upper)\n",
    "\n",
    "# Grid de hiperpar\u00e1metros (reducido para tiempo razonable)\n",
    "xgb_params_grid = {\n",
    "    \"learning_rate\": [0.01, 0.05],\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"min_child_weight\": [1, 3],\n",
    "    \"reg_lambda\": [1.0, 5.0],\n",
    "    \"aft_loss_distribution\": [\"normal\", \"logistic\"],\n",
    "}\n",
    "\n",
    "best_loss_val = float(\"inf\")\n",
    "best_params = None\n",
    "best_num_rounds = None\n",
    "\n",
    "grid = list(ParameterGrid(xgb_params_grid))\n",
    "print(f\"Evaluando {len(grid)} combinaciones para XGBoost...\")\n",
    "\n",
    "for i, params in enumerate(grid, start=1):\n",
    "    current_params = dict(params)\n",
    "    current_params.update({\n",
    "        \"objective\": \"survival:aft\",\n",
    "        \"eval_metric\": \"aft-nloglik\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"verbosity\": 0,\n",
    "        \"seed\": SEED,\n",
    "        \"nthread\": -1\n",
    "    })\n",
    "\n",
    "    cv_results = xgb.cv(\n",
    "        params=current_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=1000,\n",
    "        nfold=5,\n",
    "        stratified=False,\n",
    "        early_stopping_rounds=20,\n",
    "        verbose_eval=False,\n",
    "        seed=SEED\n",
    "    )\n",
    "\n",
    "    # \u2705 BUG FIX: la mejor ronda es el argmin, no el total de filas\n",
    "    loss_series = cv_results[\"test-aft-nloglik-mean\"]\n",
    "    mean_loss = float(loss_series.min())\n",
    "    best_round_here = int(loss_series.idxmin() + 1)\n",
    "\n",
    "    if mean_loss < best_loss_val:\n",
    "        best_loss_val = mean_loss\n",
    "        best_params = current_params\n",
    "        best_num_rounds = best_round_here\n",
    "        print(f\"   \ud83e\udd47 Nuevo mejor ({i}/{len(grid)}): Loss={mean_loss:.4f} | \"\n",
    "              f\"Dist={params['aft_loss_distribution']} | Rounds={best_num_rounds}\")\n",
    "\n",
    "print(f\"\\n\ud83c\udfc6 Mejor XGBoost Loss (aft-nloglik): {best_loss_val:.4f}\")\n",
    "print(f\"\u2699\ufe0f Mejores par\u00e1metros XGB: {best_params}\")\n",
    "print(f\"\ud83d\udd01 Mejor num_boost_round: {best_num_rounds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c60e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 4. ENTRENAR MODELO FINAL XGBOOST-AFT\n",
    "# ==============================================================================\n",
    "\n",
    "# Entrenar el modelo con los mejores hiperpar\u00e1metros y rondas \u00f3ptimas\n",
    "final_xgb = xgb.train(\n",
    "    params=best_params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=best_num_rounds\n",
    ")\n",
    "\n",
    "# Guardar modelo\n",
    "final_xgb.save_model(str(MODELS_DIR / \"best_xgb_aft.json\"))\n",
    "joblib.dump(best_params, MODELS_DIR / \"best_xgb_params.pkl\")\n",
    "print(f\"\u2705 Modelo XGBoost-AFT guardado en {MODELS_DIR / 'best_xgb_aft.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4addf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# \ud83d\udcca RESUMEN FINAL\n",
    "# ==============================================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"\ud83d\udcca RESUMEN DEL HYPERPARAMETER TUNING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n\ud83c\udf32 RANDOM SURVIVAL FOREST:\")\n",
    "print(f\"   C-index promedio: {rsf_grid.best_score_:.4f}\")\n",
    "print(f\"   Mejores par\u00e1metros:\")\n",
    "for k, v in rsf_grid.best_params_.items():\n",
    "    print(f\"      {k}: {v}\")\n",
    "\n",
    "print(f\"\\n\ud83d\ude80 XGBOOST-AFT:\")\n",
    "print(f\"   Loss (aft-nloglik): {best_loss_val:.4f}\")\n",
    "print(f\"   Distribuci\u00f3n ganadora: {best_params.get('aft_loss_distribution', 'N/A')}\")\n",
    "print(f\"   Mejor num_boost_round: {best_num_rounds}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcc1 MODELOS GUARDADOS:\")\n",
    "print(f\"   - models/best_rsf.pkl\")\n",
    "print(f\"   - models/best_xgb_aft.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\u2705 PROCESO COMPLETADO. Listo para evaluaci\u00f3n final en test set.\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}