{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdd88bca",
   "metadata": {},
   "source": [
    "# ÔøΩÔøΩ Preprocesamiento Definitivo para Survival Analysis\n",
    "\n",
    "**Versi√≥n:** MASTER (Corregida)  \n",
    "**Problema Resuelto:** Duration discreta (solo 3 valores) ‚Üí Imputaci√≥n Estoc√°stica Uniforme\n",
    "\n",
    "**Fundamento Cient√≠fico:**\n",
    "> Lawless (2003), \"Statistical Models and Methods for Lifetime Data\":\n",
    "> Datos de intervalo deben tratarse como continuos mediante imputaci√≥n para preservar varianza.\n",
    "\n",
    "**La Soluci√≥n:**\n",
    "- Convertir rangos categ√≥ricos (\"Entre 6 meses y 1 a√±o\") en valores continuos\n",
    "- Usar distribuci√≥n uniforme: $T \\sim U(lower, upper)$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee9b8dfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:05:22.763396Z",
     "iopub.status.busy": "2026-01-09T01:05:22.763265Z",
     "iopub.status.idle": "2026-01-09T01:05:23.043785Z",
     "shell.execute_reply": "2026-01-09T01:05:23.043028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuraci√≥n cargada\n",
      "   Random State: 42\n",
      "   Ventana de observaci√≥n: 30.0 meses\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 0. CONFIGURACI√ìN Y CARGA\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reproducibilidad\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Paths\n",
    "DATA_RAW = Path(\"data/raw\")\n",
    "DATA_PROCESSED = Path(\"data/processed\")\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Ventana m√°xima de observaci√≥n (meses desde graduaci√≥n hasta encuesta)\n",
    "WINDOW_SIZE = 30.0  # Asumimos encuesta hasta 30 meses post-egreso\n",
    "\n",
    "print(f\"‚úÖ Configuraci√≥n cargada\")\n",
    "print(f\"   Random State: {RANDOM_STATE}\")\n",
    "print(f\"   Ventana de observaci√≥n: {WINDOW_SIZE} meses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61819de3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:05:23.045787Z",
     "iopub.status.busy": "2026-01-09T01:05:23.045625Z",
     "iopub.status.idle": "2026-01-09T01:05:23.644030Z",
     "shell.execute_reply": "2026-01-09T01:05:23.643215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datos cargados: 380 registros\n",
      "‚úÖ Competencias t√©cnicas: 52\n"
     ]
    }
   ],
   "source": [
    "# Dependencias\n",
    "try:\n",
    "    from unidecode import unidecode\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except ImportError:\n",
    "    !pip install unidecode scikit-learn pyarrow -q\n",
    "    from unidecode import unidecode\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar datos\n",
    "df_raw = pd.read_excel(DATA_RAW / \"Encuesta recien graduados - pregrado(1).xlsx\")\n",
    "\n",
    "# Cargar diccionario de competencias\n",
    "with open(DATA_RAW / \"diccionario_maestro_stem.json\", 'r', encoding='utf-8') as f:\n",
    "    DICCIONARIO_MAESTRO = json.load(f)['competencias']\n",
    "\n",
    "print(f\"‚úÖ Datos cargados: {len(df_raw)} registros\")\n",
    "print(f\"‚úÖ Competencias t√©cnicas: {len(DICCIONARIO_MAESTRO)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b9d92",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Mapeo y Limpieza de Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c7c3bab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:05:23.646198Z",
     "iopub.status.busy": "2026-01-09T01:05:23.645801Z",
     "iopub.status.idle": "2026-01-09T01:05:23.655869Z",
     "shell.execute_reply": "2026-01-09T01:05:23.655248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Columnas mapeadas: 16\n"
     ]
    }
   ],
   "source": [
    "# Mapeo de columnas por √≠ndice\n",
    "COLUMN_MAP = {\n",
    "    0: \"edad\",\n",
    "    1: \"genero\",\n",
    "    11: \"trabaja_actualmente\",\n",
    "    15: \"tiempo_trabajando_cat\",      # CATEGOR√çA: \"Menos de 6 meses\", etc.\n",
    "    16: \"correspondencia_formacion\",\n",
    "    30: \"busca_trabajo\",\n",
    "    31: \"tiempo_buscando_cat\",        # CATEGOR√çA para desempleados\n",
    "    35: \"asignaturas_relevantes\",\n",
    "    40: \"carrera\",\n",
    "}\n",
    "\n",
    "HAB_BLANDAS_MAP = {\n",
    "    3: \"hab_gestion\",\n",
    "    4: \"hab_comunicacion\", \n",
    "    5: \"hab_liderazgo\",\n",
    "    6: \"hab_trabajo_equipo\",\n",
    "    7: \"hab_etica\",\n",
    "    8: \"hab_responsabilidad\",\n",
    "    9: \"hab_aprendizaje\"\n",
    "}\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for idx, name in {**COLUMN_MAP, **HAB_BLANDAS_MAP}.items():\n",
    "    df[name] = df_raw.iloc[:, idx]\n",
    "\n",
    "# Limpieza b√°sica\n",
    "df['trabaja_actualmente'] = df['trabaja_actualmente'].fillna('No')\n",
    "df['busca_trabajo'] = df['busca_trabajo'].fillna('No')\n",
    "df['correspondencia_formacion'] = pd.to_numeric(df['correspondencia_formacion'], errors='coerce').fillna(0)\n",
    "\n",
    "print(f\"‚úÖ Columnas mapeadas: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec3138",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Imputaci√≥n Estoc√°stica Uniforme (Lawless 2003)\n",
    "\n",
    "Convertimos categor√≠as de tiempo en valores continuos usando $T \\sim U(lower, upper)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "508c5e37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:05:23.658228Z",
     "iopub.status.busy": "2026-01-09T01:05:23.658056Z",
     "iopub.status.idle": "2026-01-09T01:05:23.666307Z",
     "shell.execute_reply": "2026-01-09T01:05:23.665490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Intervalos convertidos a continuos (Imputaci√≥n Estoc√°stica Uniforme)\n",
      "   Tenure simulada - valores √∫nicos: 210\n",
      "   B√∫squeda simulada - valores √∫nicos: 163\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# IMPUTACI√ìN DE INTERVALOS A CONTINUOS\n",
    "# ==============================================================================\n",
    "\n",
    "def parse_interval_to_range(text):\n",
    "    \"\"\"Convierte texto de encuesta a rango num√©rico [min, max] en meses.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    \n",
    "    if \"menos de 6 meses\" in text:\n",
    "        return 0.1, 6.0\n",
    "    elif \"entre 6 meses y 1 a√±o\" in text or \"de 6 meses a 1 a√±o\" in text:\n",
    "        return 6.0, 12.0\n",
    "    elif \"entre 1 y 2 a√±os\" in text or \"de 1 a√±o a 2 a√±os\" in text:\n",
    "        return 12.0, 24.0\n",
    "    elif \"m√°s de 2 a√±os\" in text or \"mas de 2 a√±os\" in text:\n",
    "        return 24.0, 30.0\n",
    "    \n",
    "    return np.nan, np.nan\n",
    "\n",
    "# 1. Simular Tenure Continua (para empleados)\n",
    "lower_t, upper_t = zip(*df['tiempo_trabajando_cat'].apply(parse_interval_to_range))\n",
    "lower_t = np.array(lower_t, dtype=float)\n",
    "upper_t = np.array(upper_t, dtype=float)\n",
    "\n",
    "# Donde hay NaN, ponemos valores neutros para evitar errores\n",
    "mask_valid_t = ~np.isnan(lower_t)\n",
    "tenure_sim = np.zeros(len(df))\n",
    "tenure_sim[mask_valid_t] = np.random.uniform(lower_t[mask_valid_t], upper_t[mask_valid_t])\n",
    "df['tenure_simulated'] = tenure_sim\n",
    "\n",
    "# 2. Simular Tiempo de B√∫squeda Continuo (para desempleados)\n",
    "lower_b, upper_b = zip(*df['tiempo_buscando_cat'].apply(parse_interval_to_range))\n",
    "lower_b = np.array(lower_b, dtype=float)\n",
    "upper_b = np.array(upper_b, dtype=float)\n",
    "\n",
    "mask_valid_b = ~np.isnan(lower_b)\n",
    "search_sim = np.zeros(len(df))\n",
    "search_sim[mask_valid_b] = np.random.uniform(lower_b[mask_valid_b], upper_b[mask_valid_b])\n",
    "df['searching_simulated'] = search_sim\n",
    "\n",
    "print(\"‚úÖ Intervalos convertidos a continuos (Imputaci√≥n Estoc√°stica Uniforme)\")\n",
    "print(f\"   Tenure simulada - valores √∫nicos: {df['tenure_simulated'].nunique()}\")\n",
    "print(f\"   B√∫squeda simulada - valores √∫nicos: {df['searching_simulated'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95327980",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Construcci√≥n del Target de Supervivencia\n",
    "\n",
    "**F√≥rmulas:**\n",
    "- Evento (E=1): Trabaja + Correspondencia ‚â• 3\n",
    "- Duration para E=1: $T = Ventana - Tenure$ (tiempo que ESPER√ì)\n",
    "- Duration para E=0: Tiempo buscando (censurado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "970e04bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:05:23.668678Z",
     "iopub.status.busy": "2026-01-09T01:05:23.668415Z",
     "iopub.status.idle": "2026-01-09T01:05:23.686041Z",
     "shell.execute_reply": "2026-01-09T01:05:23.685198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "‚úÖ TARGET CONSTRUIDO (Imputaci√≥n Estoc√°stica)\n",
      "============================================================\n",
      "Eventos (E=1):     169 (45.6%)\n",
      "Censurados (E=0):  202 (54.4%)\n",
      "\n",
      "üéØ Valores √∫nicos en duration: 332 (¬°YA NO SON 3!)\n",
      "Rango duration: [0.18, 30.00] meses\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CONSTRUCCI√ìN DE EVENT Y DURATION (CORREGIDA)\n",
    "# ==============================================================================\n",
    "\n",
    "df['event'] = 0\n",
    "df['duration'] = np.nan\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CASO 1: EVENTO - Trabaja con correspondencia >= 3\n",
    "# -----------------------------------------------------------------------------\n",
    "mask_event = (df['trabaja_actualmente'] == 'Si') & (df['correspondencia_formacion'] >= 3)\n",
    "df.loc[mask_event, 'event'] = 1\n",
    "\n",
    "# Duration = Ventana - Tenure (cu√°nto ESPER√ì antes de conseguir empleo)\n",
    "t_event = WINDOW_SIZE - df.loc[mask_event, 'tenure_simulated']\n",
    "df.loc[mask_event, 'duration'] = t_event.clip(lower=0.1)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CASO 2: CENSURADO - Busca trabajo activamente\n",
    "# -----------------------------------------------------------------------------\n",
    "mask_censored = (df['trabaja_actualmente'] == 'No') & (df['busca_trabajo'] == 'Si')\n",
    "df.loc[mask_censored, 'event'] = 0\n",
    "df.loc[mask_censored, 'duration'] = df.loc[mask_censored, 'searching_simulated'].clip(lower=0.1)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CASO 3: CENSURADO - Subempleo (trabaja pero NO relacionado)\n",
    "# -----------------------------------------------------------------------------\n",
    "mask_underemp = (df['trabaja_actualmente'] == 'Si') & (df['correspondencia_formacion'] < 3)\n",
    "df.loc[mask_underemp, 'event'] = 0\n",
    "df.loc[mask_underemp, 'duration'] = WINDOW_SIZE  # Censurado al m√°ximo\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Limpiar inactivos y NaN\n",
    "# -----------------------------------------------------------------------------\n",
    "df_clean = df.dropna(subset=['duration']).copy()\n",
    "df_clean = df_clean[df_clean['duration'] > 0].copy()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úÖ TARGET CONSTRUIDO (Imputaci√≥n Estoc√°stica)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Eventos (E=1):     {(df_clean['event'] == 1).sum()} ({100*(df_clean['event'] == 1).mean():.1f}%)\")\n",
    "print(f\"Censurados (E=0):  {(df_clean['event'] == 0).sum()} ({100*(df_clean['event'] == 0).mean():.1f}%)\")\n",
    "print(f\"\\nüéØ Valores √∫nicos en duration: {df_clean['duration'].nunique()} (¬°YA NO SON 3!)\")\n",
    "print(f\"Rango duration: [{df_clean['duration'].min():.2f}, {df_clean['duration'].max():.2f}] meses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "918b3578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:05:23.687872Z",
     "iopub.status.busy": "2026-01-09T01:05:23.687558Z",
     "iopub.status.idle": "2026-01-09T01:05:23.695128Z",
     "shell.execute_reply": "2026-01-09T01:05:23.694351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Correlaci√≥n event-duration: 0.5105\n",
      "   (Antes era -0.93, ahora debe ser menor en magnitud)\n",
      "\n",
      "üìä Distribuci√≥n de duration:\n",
      "count    371.00\n",
      "mean      15.54\n",
      "std       11.10\n",
      "min        0.18\n",
      "25%        4.23\n",
      "50%       17.44\n",
      "75%       26.37\n",
      "max       30.00\n",
      "Name: duration, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Verificar que ya no hay colinealidad perfecta\n",
    "corr = df_clean[['event', 'duration']].corr().iloc[0, 1]\n",
    "print(f\"\\nüîç Correlaci√≥n event-duration: {corr:.4f}\")\n",
    "print(f\"   (Antes era -0.93, ahora debe ser menor en magnitud)\")\n",
    "\n",
    "# Histograma r√°pido\n",
    "print(f\"\\nüìä Distribuci√≥n de duration:\")\n",
    "print(df_clean['duration'].describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c0abf0",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Extracci√≥n de Soft Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97c7c7fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:05:23.697138Z",
     "iopub.status.busy": "2026-01-09T01:05:23.696837Z",
     "iopub.status.idle": "2026-01-09T01:05:23.717993Z",
     "shell.execute_reply": "2026-01-09T01:05:23.717258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Soft Skills extra√≠das (Likert 1-5)\n",
      "       hab_gestion  hab_comunicacion  hab_liderazgo  hab_trabajo_equipo  \\\n",
      "count       371.00             371.0          371.0              371.00   \n",
      "mean          3.71               3.4            3.7                3.84   \n",
      "\n",
      "       hab_etica  hab_responsabilidad  hab_aprendizaje  \n",
      "count     371.00               371.00           371.00  \n",
      "mean        4.13                 3.84             4.29  \n"
     ]
    }
   ],
   "source": [
    "# Extraer valores Likert\n",
    "def extract_likert(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    match = re.search(r'^(\\d)', str(value))\n",
    "    return int(match.group(1)) if match else np.nan\n",
    "\n",
    "HAB_COLS = list(HAB_BLANDAS_MAP.values())\n",
    "for col in HAB_COLS:\n",
    "    df_clean[col] = df_clean[col].apply(extract_likert)\n",
    "\n",
    "print(\"‚úÖ Soft Skills extra√≠das (Likert 1-5)\")\n",
    "print(df_clean[HAB_COLS].describe().loc[['count', 'mean']].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c74cdf4",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Vectorizaci√≥n de Habilidades T√©cnicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c29ee117",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:05:23.719850Z",
     "iopub.status.busy": "2026-01-09T01:05:23.719700Z",
     "iopub.status.idle": "2026-01-09T01:05:24.115996Z",
     "shell.execute_reply": "2026-01-09T01:05:24.115220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 52 competencias t√©cnicas vectorizadas\n"
     ]
    }
   ],
   "source": [
    "# Matching con diccionario controlado\n",
    "def match_skills(texto, diccionario):\n",
    "    if pd.isna(texto):\n",
    "        return []\n",
    "    texto = unidecode(str(texto).lower())\n",
    "    matches = []\n",
    "    for skill_id, skill_info in diccionario.items():\n",
    "        for alias in skill_info['aliases']:\n",
    "            if unidecode(alias.lower()) in texto:\n",
    "                matches.append(skill_id)\n",
    "                break\n",
    "    return list(set(matches))\n",
    "\n",
    "# Crear columnas binarias\n",
    "SKILLS_LIST = list(DICCIONARIO_MAESTRO.keys())\n",
    "for skill in SKILLS_LIST:\n",
    "    df_clean[f\"tech_{skill}\"] = 0\n",
    "\n",
    "for idx, row in df_clean.iterrows():\n",
    "    for skill in match_skills(row[\"asignaturas_relevantes\"], DICCIONARIO_MAESTRO):\n",
    "        df_clean.loc[idx, f\"tech_{skill}\"] = 1\n",
    "\n",
    "TECH_COLS = [f\"tech_{s}\" for s in SKILLS_LIST]\n",
    "print(f\"‚úÖ {len(TECH_COLS)} competencias t√©cnicas vectorizadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c28798",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Split Estratificado y Escalado (Sin Data Leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6d2eb45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:05:24.117670Z",
     "iopub.status.busy": "2026-01-09T01:05:24.117502Z",
     "iopub.status.idle": "2026-01-09T01:05:24.133136Z",
     "shell.execute_reply": "2026-01-09T01:05:24.132289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Split realizado:\n",
      "   Train: 296 | Test: 75\n",
      "‚úÖ Escalado aplicado (sin data leakage)\n"
     ]
    }
   ],
   "source": [
    "# Preparar features\n",
    "df_clean['genero_m'] = (df_clean['genero'].str.lower() == 'masculino').astype(int)\n",
    "df_clean['edad'] = pd.to_numeric(df_clean['edad'], errors='coerce')\n",
    "\n",
    "FEATURE_COLS = ['edad', 'genero_m'] + HAB_COLS + TECH_COLS\n",
    "\n",
    "# Split estratificado por event\n",
    "X = df_clean[FEATURE_COLS].copy()\n",
    "y = df_clean[['event', 'duration']].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y['event']\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Split realizado:\")\n",
    "print(f\"   Train: {len(X_train)} | Test: {len(X_test)}\")\n",
    "\n",
    "# Escalado SOLO fit en train\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Imputar NaN con mediana de train\n",
    "for col in HAB_COLS + ['edad']:\n",
    "    train_median = X_train[col].median()\n",
    "    X_train[col] = X_train[col].fillna(train_median)\n",
    "    X_test[col] = X_test[col].fillna(train_median)\n",
    "\n",
    "# Fit en train, transform en ambos\n",
    "scaler.fit(X_train[HAB_COLS])\n",
    "X_train[HAB_COLS] = scaler.transform(X_train[HAB_COLS])\n",
    "X_test[HAB_COLS] = scaler.transform(X_test[HAB_COLS])\n",
    "\n",
    "print(\"‚úÖ Escalado aplicado (sin data leakage)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad8ec6e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:05:24.134888Z",
     "iopub.status.busy": "2026-01-09T01:05:24.134628Z",
     "iopub.status.idle": "2026-01-09T01:05:24.156851Z",
     "shell.execute_reply": "2026-01-09T01:05:24.156287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üöÄ PREPROCESAMIENTO COMPLETADO\n",
      "============================================================\n",
      "\n",
      "üìÅ Archivos guardados:\n",
      "   - train_survival_final.parquet (296 registros)\n",
      "   - test_survival_final.parquet (75 registros)\n",
      "\n",
      "üìê Features: 61\n",
      "üéØ Duration valores √∫nicos: 265\n",
      "\n",
      "‚úÖ Correlaci√≥n event-duration: 0.5079\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Concatenar y guardar\n",
    "train_final = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\n",
    "test_final = pd.concat([X_test.reset_index(drop=True), y_test.reset_index(drop=True)], axis=1)\n",
    "\n",
    "train_final.to_parquet(DATA_PROCESSED / \"train_survival_final.parquet\", index=False)\n",
    "test_final.to_parquet(DATA_PROCESSED / \"test_survival_final.parquet\", index=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üöÄ PREPROCESAMIENTO COMPLETADO\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìÅ Archivos guardados:\")\n",
    "print(f\"   - train_survival_final.parquet ({len(train_final)} registros)\")\n",
    "print(f\"   - test_survival_final.parquet ({len(test_final)} registros)\")\n",
    "print(f\"\\nüìê Features: {len(FEATURE_COLS)}\")\n",
    "print(f\"üéØ Duration valores √∫nicos: {train_final['duration'].nunique()}\")\n",
    "print(f\"\\n‚úÖ Correlaci√≥n event-duration: {train_final[['event','duration']].corr().iloc[0,1]:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
