{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31039404",
   "metadata": {},
   "source": [
    "# ÔøΩÔøΩ Feature Selection y Entrenamiento Final\n",
    "\n",
    "**Versi√≥n:** v2  \n",
    "**Entrada:** `./data/processed/train_final.parquet`, `test_final.parquet`  \n",
    "**Objetivo:** Seleccionar Top-20 features y entrenar modelos de supervivencia\n",
    "\n",
    "---\n",
    "\n",
    "## Justificaci√≥n Metodol√≥gica (Basada en el Corpus)\n",
    "\n",
    "### 1. Reducci√≥n de Dimensionalidad\n",
    "\n",
    "> **\"Ante la alta dimensionalidad (60+ features), aplicamos Permutation Importance con un Random Forest base para seleccionar las variables con poder predictivo real, descartando ruido (Hastie et al., 2009).\"**\n",
    "\n",
    "| Paper del Corpus | Justificaci√≥n |\n",
    "|------------------|---------------|\n",
    "| Barnwal et al. (2022) *Survival Regression with Accelerated Failure Time* | XGBoost-AFT para datos censurados |\n",
    "| Andonovikj et al. (2024) *Survival Analysis as Semi-Supervised* | Feature selection en survival |\n",
    "| Abd ElHafeez (2021) *Methods to Analyze Time-to-Event Data* | Cox regression y C-index |\n",
    "| Getie Ayaneh (2020) *Survival Models for Waiting Time* | Aplicaci√≥n a empleabilidad |\n",
    "\n",
    "### 2. Modelos a Entrenar\n",
    "\n",
    "- **Random Survival Forest (RSF)**: Ensemble robusto para datos censurados\n",
    "- **XGBoost-AFT**: Accelerated Failure Time con regularizaci√≥n\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140deef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CONFIGURACI√ìN\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "DATA_DIR = Path(\"data/processed\")\n",
    "MODELS_DIR = Path(\"models\")\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n cargada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fd2f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "train = pd.read_parquet(DATA_DIR / \"train_final.parquet\")\n",
    "test = pd.read_parquet(DATA_DIR / \"test_final.parquet\")\n",
    "\n",
    "# Separar features y target\n",
    "feature_cols = [c for c in train.columns if c not in ['event', 'duration']]\n",
    "X_train = train[feature_cols]\n",
    "y_train_event = train['event']\n",
    "y_train_duration = train['duration']\n",
    "\n",
    "X_test = test[feature_cols]\n",
    "y_test_event = test['event']\n",
    "y_test_duration = test['duration']\n",
    "\n",
    "print(f\"‚úÖ Datos cargados:\")\n",
    "print(f\"   Train: {X_train.shape} | Test: {X_test.shape}\")\n",
    "print(f\"   Features: {len(feature_cols)}\")\n",
    "print(f\"   Event rate train: {y_train_event.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b664ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports para ML\n",
    "import xgboost as xgb\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "print(\"‚úÖ Librer√≠as ML cargadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f9deef",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Feature Selection con Permutation Importance\n",
    "\n",
    "Usamos un RandomForest para identificar las 20 variables m√°s importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19708d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FEATURE IMPORTANCE CON RANDOM FOREST\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"üîç Calculando Feature Importance...\")\n",
    "\n",
    "# Entrenar RF r√°pido para obtener importancia\n",
    "rf_baseline = RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf_baseline.fit(X_train, y_train_duration)\n",
    "\n",
    "# Obtener importancia\n",
    "importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_baseline.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nüìä Top 20 Features por Importancia:\")\n",
    "print(importance.head(20).to_string(index=False))\n",
    "\n",
    "# Seleccionar Top 20\n",
    "TOP_K = 20\n",
    "top_features = importance.head(TOP_K)['feature'].tolist()\n",
    "print(f\"\\n‚úÖ Seleccionadas {TOP_K} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducir a Top-K features\n",
    "X_train_sel = X_train[top_features]\n",
    "X_test_sel = X_test[top_features]\n",
    "\n",
    "print(f\"‚úÖ Dimensiones reducidas:\")\n",
    "print(f\"   Train: {X_train_sel.shape}\")\n",
    "print(f\"   Test: {X_test_sel.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04114ee",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Entrenamiento: Random Survival Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1315d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# RANDOM SURVIVAL FOREST\n",
    "# ==============================================================================\n",
    "\n",
    "# Formato Scikit-Survival\n",
    "y_train_surv = Surv.from_arrays(y_train_event.astype(bool), y_train_duration)\n",
    "y_test_surv = Surv.from_arrays(y_test_event.astype(bool), y_test_duration)\n",
    "\n",
    "# Entrenar RSF con mejores hiperpar√°metros del tuning previo\n",
    "print(\"üå≤ Entrenando Random Survival Forest...\")\n",
    "\n",
    "rsf = RandomSurvivalForest(\n",
    "    n_estimators=500,\n",
    "    min_samples_leaf=20,\n",
    "    max_depth=None,\n",
    "    max_features='sqrt',\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rsf.fit(X_train_sel, y_train_surv)\n",
    "\n",
    "# Evaluaci√≥n en TEST\n",
    "rsf_pred = rsf.predict(X_test_sel)\n",
    "c_index_rsf = concordance_index_censored(\n",
    "    y_test_event.astype(bool), \n",
    "    y_test_duration, \n",
    "    rsf_pred\n",
    ")[0]\n",
    "\n",
    "print(f\"\\nüèÜ RSF C-index (TEST): {c_index_rsf:.4f}\")\n",
    "\n",
    "# Guardar modelo\n",
    "joblib.dump(rsf, MODELS_DIR / \"rsf_final.pkl\")\n",
    "print(f\"‚úÖ Modelo guardado: {MODELS_DIR / 'rsf_final.pkl'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ad1ce7",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Entrenamiento: XGBoost-AFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# XGBOOST AFT\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"üöÄ Entrenando XGBoost-AFT...\")\n",
    "\n",
    "# Preparar bounds para AFT\n",
    "def make_aft_bounds(event, duration):\n",
    "    y_lower = duration.values.astype(float)\n",
    "    y_upper = duration.values.astype(float).copy()\n",
    "    y_upper[event.values == 0] = np.inf\n",
    "    return y_lower, y_upper\n",
    "\n",
    "y_lower_train, y_upper_train = make_aft_bounds(y_train_event, y_train_duration)\n",
    "y_lower_test, y_upper_test = make_aft_bounds(y_test_event, y_test_duration)\n",
    "\n",
    "# DMatrix\n",
    "dtrain = xgb.DMatrix(X_train_sel)\n",
    "dtrain.set_float_info('label_lower_bound', y_lower_train)\n",
    "dtrain.set_float_info('label_upper_bound', y_upper_train)\n",
    "\n",
    "dtest = xgb.DMatrix(X_test_sel)\n",
    "dtest.set_float_info('label_lower_bound', y_lower_test)\n",
    "dtest.set_float_info('label_upper_bound', y_upper_test)\n",
    "\n",
    "# Par√°metros √≥ptimos del tuning\n",
    "xgb_params = {\n",
    "    'objective': 'survival:aft',\n",
    "    'eval_metric': 'aft-nloglik',\n",
    "    'aft_loss_distribution': 'normal',\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "    'reg_lambda': 5.0,\n",
    "    'tree_method': 'hist',\n",
    "    'seed': RANDOM_STATE\n",
    "}\n",
    "\n",
    "# Entrenar\n",
    "xgb_model = xgb.train(xgb_params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Predicci√≥n (tiempo esperado)\n",
    "xgb_pred = xgb_model.predict(dtest)\n",
    "\n",
    "# C-index para XGBoost (predicci√≥n de tiempo, mayor = evento m√°s tarde)\n",
    "c_index_xgb = concordance_index_censored(\n",
    "    y_test_event.astype(bool),\n",
    "    y_test_duration,\n",
    "    -xgb_pred  # Negativo porque mayor tiempo = menor riesgo\n",
    ")[0]\n",
    "\n",
    "print(f\"\\nüèÜ XGBoost-AFT C-index (TEST): {c_index_xgb:.4f}\")\n",
    "\n",
    "# Guardar\n",
    "xgb_model.save_model(str(MODELS_DIR / \"xgb_aft_final.json\"))\n",
    "print(f\"‚úÖ Modelo guardado: {MODELS_DIR / 'xgb_aft_final.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af31359",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Resumen de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310bbcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# RESUMEN FINAL\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä RESULTADOS FINALES EN TEST SET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "üéØ M√âTRICAS DE EVALUACI√ìN (C-index)\n",
    "\n",
    "| Modelo          | C-index (Test) | Interpretaci√≥n |\n",
    "|-----------------|----------------|----------------|\n",
    "| RSF             | {c_index_rsf:.4f}         | {'‚úÖ Bueno' if c_index_rsf > 0.6 else '‚ö†Ô∏è Moderado' if c_index_rsf > 0.55 else '‚ùå Bajo'} |\n",
    "| XGBoost-AFT     | {c_index_xgb:.4f}         | {'‚úÖ Bueno' if c_index_xgb > 0.6 else '‚ö†Ô∏è Moderado' if c_index_xgb > 0.55 else '‚ùå Bajo'} |\n",
    "\n",
    "üìå Referencia C-index:\n",
    "   0.50 = Aleatorio\n",
    "   0.60 = Aceptable\n",
    "   0.70 = Bueno\n",
    "   0.80 = Excelente\n",
    "\n",
    "üìÅ MODELOS GUARDADOS:\n",
    "   - models/rsf_final.pkl\n",
    "   - models/xgb_aft_final.json\n",
    "\n",
    "üîç FEATURES SELECCIONADAS ({TOP_K}):\n",
    "\"\"\")\n",
    "\n",
    "for i, f in enumerate(top_features, 1):\n",
    "    print(f\"   {i:2d}. {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61fb578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar lista de features seleccionadas\n",
    "import json\n",
    "\n",
    "feature_selection_info = {\n",
    "    'top_features': top_features,\n",
    "    'c_index_rsf': float(c_index_rsf),\n",
    "    'c_index_xgb': float(c_index_xgb),\n",
    "    'n_train': len(X_train),\n",
    "    'n_test': len(X_test)\n",
    "}\n",
    "\n",
    "with open(MODELS_DIR / 'feature_selection_results.json', 'w') as f:\n",
    "    json.dump(feature_selection_info, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Resultados guardados en {MODELS_DIR / 'feature_selection_results.json'}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
