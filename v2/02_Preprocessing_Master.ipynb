{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "715d1c16",
   "metadata": {},
   "source": [
    "# ï¿½ï¿½ Preprocesamiento Master para Survival Analysis\n",
    "\n",
    "**VersiÃ³n:** v2 (Definitiva)  \n",
    "**Entrada:** `./data/processed/clean_survey_data.csv`  \n",
    "**Salida:** `train_final.parquet`, `test_final.parquet`\n",
    "\n",
    "---\n",
    "\n",
    "## JustificaciÃ³n MetodolÃ³gica (Basada en el Corpus CientÃ­fico)\n",
    "\n",
    "### 1. VectorizaciÃ³n de Competencias TÃ©cnicas (52D)\n",
    "\n",
    "> **\"Para los vectores de habilidades, rechazamos variables agregadas y usamos competencias especÃ­ficas (52D) siguiendo a BÃ¶rner et al. (2018) y Jang (2015), capturando la varianza intra-clase.\"**\n",
    "\n",
    "### 2. ImputaciÃ³n EstocÃ¡stica Uniforme\n",
    "\n",
    "> **\"Para la variable tiempo, aplicamos ImputaciÃ³n EstocÃ¡stica Uniforme (Lawless, 2003) para convertir los rangos de la encuesta (interval-censored) en variables continuas, evitando la colinealidad artificial.\"**\n",
    "\n",
    "### 3. DefiniciÃ³n del Evento\n",
    "\n",
    "> **Definimos E=1 cuando el graduado obtiene empleo STEM con correspondencia â‰¥3 (Getie Ayaneh et al., 2020).**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bee8afeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:39:34.474650Z",
     "iopub.status.busy": "2026-01-09T01:39:34.474461Z",
     "iopub.status.idle": "2026-01-09T01:39:34.726665Z",
     "shell.execute_reply": "2026-01-09T01:39:34.726196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ConfiguraciÃ³n cargada\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CONFIGURACIÃ“N\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "DATA_CLEAN = Path(\"data/processed/clean_survey_data.csv\")\n",
    "DICT_PATH = Path(\"../diccionario_maestro_stem.json\")\n",
    "OUTPUT_DIR = Path(\"data/processed\")\n",
    "WINDOW_SIZE = 30.0\n",
    "\n",
    "print(\"âœ… ConfiguraciÃ³n cargada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de0aba23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:39:34.728723Z",
     "iopub.status.busy": "2026-01-09T01:39:34.728503Z",
     "iopub.status.idle": "2026-01-09T01:39:35.096584Z",
     "shell.execute_reply": "2026-01-09T01:39:35.096059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Datos: 380 registros | Competencias: 52\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from unidecode import unidecode\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except ImportError:\n",
    "    !pip install unidecode scikit-learn pyarrow -q\n",
    "    from unidecode import unidecode\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(DATA_CLEAN)\n",
    "with open(DICT_PATH, 'r', encoding='utf-8') as f:\n",
    "    DICCIONARIO_MAESTRO = json.load(f)['competencias']\n",
    "\n",
    "print(f\"âœ… Datos: {len(df)} registros | Competencias: {len(DICCIONARIO_MAESTRO)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff3e339",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:39:35.098287Z",
     "iopub.status.busy": "2026-01-09T01:39:35.098098Z",
     "iopub.status.idle": "2026-01-09T01:39:35.103238Z",
     "shell.execute_reply": "2026-01-09T01:39:35.102272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Columnas mapeadas por Ã­ndice\n",
      "   Trabaja [11]: {'Si': 209, 'No': 171}\n",
      "   Correspondencia [16]: valores 1-4\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# MAPEO DE COLUMNAS POR ÃNDICE (Estructura fija del CSV)\n",
    "# ==============================================================================\n",
    "\n",
    "# Columnas identificadas por posiciÃ³n\n",
    "COL_EDAD = df.columns[0]           # [0] 1.1 Edad\n",
    "COL_GENERO = df.columns[1]         # [1] 1.2 GÃ©nero\n",
    "HAB_COLS_RAW = df.columns[3:10].tolist()  # [3-9] Soft skills\n",
    "COL_TRABAJA = df.columns[11]       # [11] 4.1 Â¿Actualmente estÃ¡s trabajando?\n",
    "COL_TIEMPO_TRABAJO = df.columns[15]  # [15] 4.1.5 Tiempo trabajando\n",
    "COL_CORRESPONDENCIA = df.columns[16]  # [16] 4.1.6 Correspondencia 1-4\n",
    "COL_BUSCA = df.columns[30]         # [30] 4.1.12 Â¿Buscando trabajo?\n",
    "COL_TIEMPO_BUSCA = df.columns[31]  # [31] 4.1.13 Tiempo buscando\n",
    "COL_ASIGNATURAS = df.columns[35]   # [35] 6.1 Asignaturas relevantes\n",
    "\n",
    "print(\"âœ… Columnas mapeadas por Ã­ndice\")\n",
    "print(f\"   Trabaja [{11}]: {df[COL_TRABAJA].value_counts().to_dict()}\")\n",
    "print(f\"   Correspondencia [{16}]: valores 1-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a99ac",
   "metadata": {},
   "source": [
    "---\n",
    "## ImputaciÃ³n EstocÃ¡stica Uniforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53d52116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:39:35.104938Z",
     "iopub.status.busy": "2026-01-09T01:39:35.104640Z",
     "iopub.status.idle": "2026-01-09T01:39:35.111979Z",
     "shell.execute_reply": "2026-01-09T01:39:35.111369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ImputaciÃ³n: Tenure 210 Ãºnicos, Search 163 Ãºnicos\n"
     ]
    }
   ],
   "source": [
    "def parse_interval(text):\n",
    "    if pd.isna(text): return np.nan, np.nan\n",
    "    text = str(text).lower()\n",
    "    if \"menos de 6\" in text: return 0.5, 6.0\n",
    "    elif \"6 meses\" in text and \"1 aÃ±o\" in text: return 6.0, 12.0\n",
    "    elif \"1\" in text and \"2 aÃ±os\" in text: return 12.0, 24.0\n",
    "    elif \"mÃ¡s de 2\" in text or \"mas de 2\" in text: return 24.0, 30.0\n",
    "    return np.nan, np.nan\n",
    "\n",
    "# Tenure (empleados)\n",
    "lower_t, upper_t = zip(*df[COL_TIEMPO_TRABAJO].apply(parse_interval))\n",
    "lower_t, upper_t = np.array(lower_t, float), np.array(upper_t, float)\n",
    "mask = ~np.isnan(lower_t)\n",
    "tenure = np.zeros(len(df))\n",
    "tenure[mask] = np.random.uniform(lower_t[mask], upper_t[mask])\n",
    "df['tenure_sim'] = tenure\n",
    "\n",
    "# BÃºsqueda (desempleados)\n",
    "lower_b, upper_b = zip(*df[COL_TIEMPO_BUSCA].apply(parse_interval))\n",
    "lower_b, upper_b = np.array(lower_b, float), np.array(upper_b, float)\n",
    "mask = ~np.isnan(lower_b)\n",
    "search = np.zeros(len(df))\n",
    "search[mask] = np.random.uniform(lower_b[mask], upper_b[mask])\n",
    "df['search_sim'] = search\n",
    "\n",
    "print(f\"âœ… ImputaciÃ³n: Tenure {df['tenure_sim'].nunique()} Ãºnicos, Search {df['search_sim'].nunique()} Ãºnicos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afee4820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:39:35.113338Z",
     "iopub.status.busy": "2026-01-09T01:39:35.113207Z",
     "iopub.status.idle": "2026-01-09T01:39:35.127945Z",
     "shell.execute_reply": "2026-01-09T01:39:35.127259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VerificaciÃ³n: Trabaja=Si: 209, Correspondencia>=3: 169\n",
      "\n",
      "âœ… TARGET:\n",
      "   Eventos: 169 (45.6%)\n",
      "   Censurados: 202\n",
      "   Duration Ãºnicos: 332\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CONSTRUCCIÃ“N DE EVENT Y DURATION\n",
    "# ==============================================================================\n",
    "\n",
    "df['event'] = 0\n",
    "df['duration'] = np.nan\n",
    "\n",
    "# Normalizar columnas\n",
    "trabaja = df[COL_TRABAJA].astype(str).str.strip().str.lower() == 'si'\n",
    "correspondencia = pd.to_numeric(df[COL_CORRESPONDENCIA], errors='coerce').fillna(0)\n",
    "busca = df[COL_BUSCA].astype(str).str.strip().str.lower() == 'si'\n",
    "\n",
    "print(f\"VerificaciÃ³n: Trabaja=Si: {trabaja.sum()}, Correspondencia>=3: {(correspondencia>=3).sum()}\")\n",
    "\n",
    "# EVENTO: Trabaja + Correspondencia >= 3\n",
    "mask_event = trabaja & (correspondencia >= 3)\n",
    "df.loc[mask_event, 'event'] = 1\n",
    "df.loc[mask_event, 'duration'] = (WINDOW_SIZE - df.loc[mask_event, 'tenure_sim']).clip(lower=0.1)\n",
    "\n",
    "# CENSURADO: No trabaja pero busca\n",
    "mask_censored = (~trabaja) & busca\n",
    "df.loc[mask_censored, 'event'] = 0\n",
    "df.loc[mask_censored, 'duration'] = df.loc[mask_censored, 'search_sim'].clip(lower=0.1)\n",
    "\n",
    "# CENSURADO: Subempleo\n",
    "mask_sub = trabaja & (correspondencia < 3)\n",
    "df.loc[mask_sub, 'event'] = 0\n",
    "df.loc[mask_sub, 'duration'] = WINDOW_SIZE\n",
    "\n",
    "# Limpiar\n",
    "df_clean = df.dropna(subset=['duration']).copy()\n",
    "df_clean = df_clean[df_clean['duration'] > 0].copy()\n",
    "\n",
    "print(f\"\\nâœ… TARGET:\")\n",
    "print(f\"   Eventos: {(df_clean['event']==1).sum()} ({100*(df_clean['event']==1).mean():.1f}%)\")\n",
    "print(f\"   Censurados: {(df_clean['event']==0).sum()}\")\n",
    "print(f\"   Duration Ãºnicos: {df_clean['duration'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7b0c8c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:39:35.129567Z",
     "iopub.status.busy": "2026-01-09T01:39:35.129376Z",
     "iopub.status.idle": "2026-01-09T01:39:35.139847Z",
     "shell.execute_reply": "2026-01-09T01:39:35.139086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 7 Soft Skills extraÃ­das\n"
     ]
    }
   ],
   "source": [
    "def extract_likert(v):\n",
    "    if pd.isna(v): return np.nan\n",
    "    m = re.search(r'^(\\d)', str(v))\n",
    "    return int(m.group(1)) if m else np.nan\n",
    "\n",
    "HAB_COLS = []\n",
    "for i, col in enumerate(HAB_COLS_RAW):\n",
    "    name = f\"hab_{i+1}\"\n",
    "    df_clean[name] = df_clean[col].apply(extract_likert)\n",
    "    HAB_COLS.append(name)\n",
    "\n",
    "print(f\"âœ… {len(HAB_COLS)} Soft Skills extraÃ­das\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3dd69ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:39:35.141559Z",
     "iopub.status.busy": "2026-01-09T01:39:35.141359Z",
     "iopub.status.idle": "2026-01-09T01:39:35.523234Z",
     "shell.execute_reply": "2026-01-09T01:39:35.522142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 52 Tech Skills | Cobertura: 96.2%\n"
     ]
    }
   ],
   "source": [
    "def match_skills(texto, dic):\n",
    "    if pd.isna(texto): return []\n",
    "    texto = unidecode(str(texto).lower())\n",
    "    return list(set(k for k, v in dic.items() for a in v.get('aliases',[]) if unidecode(a.lower()) in texto))\n",
    "\n",
    "SKILLS = list(DICCIONARIO_MAESTRO.keys())\n",
    "TECH_COLS = [f\"tech_{s}\" for s in SKILLS]\n",
    "\n",
    "for s in SKILLS:\n",
    "    df_clean[f\"tech_{s}\"] = 0\n",
    "\n",
    "for idx in df_clean.index:\n",
    "    for s in match_skills(df_clean.loc[idx, COL_ASIGNATURAS], DICCIONARIO_MAESTRO):\n",
    "        df_clean.loc[idx, f\"tech_{s}\"] = 1\n",
    "\n",
    "print(f\"âœ… {len(TECH_COLS)} Tech Skills | Cobertura: {(df_clean[TECH_COLS].sum(1)>0).mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d6ac417",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:39:35.525236Z",
     "iopub.status.busy": "2026-01-09T01:39:35.525057Z",
     "iopub.status.idle": "2026-01-09T01:39:35.540274Z",
     "shell.execute_reply": "2026-01-09T01:39:35.539554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train: 296 | Test: 75\n"
     ]
    }
   ],
   "source": [
    "df_clean['genero_m'] = df_clean[COL_GENERO].astype(str).str.lower().str.contains('masculino').astype(int)\n",
    "df_clean['edad'] = pd.to_numeric(df_clean[COL_EDAD], errors='coerce')\n",
    "\n",
    "FEATURES = ['edad', 'genero_m'] + HAB_COLS + TECH_COLS\n",
    "X = df_clean[FEATURES].copy()\n",
    "y = df_clean[['event', 'duration']].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y['event'])\n",
    "\n",
    "# Escalado\n",
    "scaler = MinMaxScaler()\n",
    "for c in HAB_COLS + ['edad']:\n",
    "    med = X_train[c].median()\n",
    "    X_train[c] = X_train[c].fillna(med)\n",
    "    X_test[c] = X_test[c].fillna(med)\n",
    "\n",
    "scaler.fit(X_train[HAB_COLS])\n",
    "X_train[HAB_COLS] = scaler.transform(X_train[HAB_COLS])\n",
    "X_test[HAB_COLS] = scaler.transform(X_test[HAB_COLS])\n",
    "\n",
    "print(f\"âœ… Train: {len(X_train)} | Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02fc1eab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T01:39:35.541832Z",
     "iopub.status.busy": "2026-01-09T01:39:35.541649Z",
     "iopub.status.idle": "2026-01-09T01:39:35.563281Z",
     "shell.execute_reply": "2026-01-09T01:39:35.562700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸš€ PREPROCESAMIENTO COMPLETADO\n",
      "============================================================\n",
      "Train: 296 | Test: 75\n",
      "Features: 61\n",
      "Duration Ãºnicos: 265\n",
      "Event rate: 45.6%\n",
      "CorrelaciÃ³n E-D: 0.5040\n"
     ]
    }
   ],
   "source": [
    "train = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1)\n",
    "test = pd.concat([X_test.reset_index(drop=True), y_test.reset_index(drop=True)], axis=1)\n",
    "\n",
    "train.to_parquet(OUTPUT_DIR / \"train_final.parquet\", index=False)\n",
    "test.to_parquet(OUTPUT_DIR / \"test_final.parquet\", index=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸš€ PREPROCESAMIENTO COMPLETADO\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Train: {len(train)} | Test: {len(test)}\")\n",
    "print(f\"Features: {len(FEATURES)}\")\n",
    "print(f\"Duration Ãºnicos: {train['duration'].nunique()}\")\n",
    "print(f\"Event rate: {train['event'].mean():.1%}\")\n",
    "print(f\"CorrelaciÃ³n E-D: {train[['event','duration']].corr().iloc[0,1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
